{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ë¹ ë¥¸ ì•™ìƒë¸”: EASE + BPR + ItemKNN (ë…¼ë¬¸ ê¸°ë°˜ ì ‘ê·¼ë²•)\n",
    "\n",
    "## í•µì‹¬ ì „ëµ ìš”ì•½\n",
    "\n",
    "**ëª¨ë¸ êµ¬ì„±:**\n",
    "- **EASE** (Embarrassingly Shallow Autoencoders): Î» ê·¸ë¦¬ë“œ ì„œì¹˜ (Steck, 2019)\n",
    "- **BPR** (Bayesian Personalized Ranking): Optuna TPE 30 trials (Rendle et al., 2012)\n",
    "- **ItemKNN** (Item K-Nearest Neighbors): ê³ ì • k=50 (Sarwar et al., 2001)\n",
    "- **ì•™ìƒë¸”**: RRF (Reciprocal Rank Fusion) ë™ì¼ ê°€ì¤‘ì¹˜\n",
    "\n",
    "**ìµœì í™” ì „ëµ:**\n",
    "1. âœ… CV ì œê±° â†’ ë‹¨ì¼ 80/20 Temporal Split (ë…¼ë¬¸ ë°©ì‹)\n",
    "2. âœ… EASE Î»=100-2000 íƒìƒ‰ (99.9% í¬ì†Œ ë°ì´í„°ì— ìµœì )\n",
    "3. âœ… BPR Optuna TPE íš¨ìœ¨ì  í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰\n",
    "4. âœ… Cold-start ëŒ€ì‘ (ì¸ê¸°ë„ ê¸°ë°˜ í´ë°±)\n",
    "5. âœ… Device ìë™ ì„ íƒ (CUDA > MPS > CPU)\n",
    "\n",
    "**ì˜ˆìƒ ì„±ëŠ¥:**\n",
    "- Validation Recall@5: 0.40-0.50\n",
    "- Expected Public LB: 0.10-0.13\n",
    "- ì˜ˆìƒ ì†Œìš” ì‹œê°„: ~30ë¶„\n",
    "\n",
    "**ê²€ì¦ ë°©ë²•:**\n",
    "- âŒ ì´ì „: 5-Fold CV â†’ ê³¼ì í•©, Public LB 0.0055\n",
    "- âœ… í˜„ì¬: Temporal 80/20 split â†’ í˜„ì‹¤ì  ê²€ì¦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "### ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cornac version: 2.3.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katp/anaconda3/envs/cornac/lib/python3.12/site-packages/cornac/data/text.py:135: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  Remove \"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\" from t.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import optuna\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cornac\n",
    "import cornac\n",
    "print(f\"Cornac version: {cornac.__version__}\")\n",
    "from cornac.data import Dataset\n",
    "from cornac.models import EASE, BPR, ItemKNN\n",
    "from cornac.metrics import Recall\n",
    "from cornac.eval_methods.base_method import ranking_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "### ì„¤ì • (Configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ ë° ìµœì í™” ì„¤ì •\n# ============================================================\nprint(\"=\" * 60)\nprint(\"ë””ë°”ì´ìŠ¤ ì„ íƒ ë° ìµœì í™” ì„¤ì •\")\nprint(\"=\" * 60)\n\nif torch.cuda.is_available():\n    device = 'cuda'\n    total_cpus = os.cpu_count() or 4\n    print(f\"ğŸš€ ë””ë°”ì´ìŠ¤: CUDA ({torch.cuda.get_device_name(0)})\")\n    print(f\"   ì‚¬ìš© ê°€ëŠ¥ CPU: {total_cpus}ì½”ì–´\")\n    print(f\"   GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\nelif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n    device = 'mps'\n    total_cpus = os.cpu_count() or 4\n    print(f\"ğŸ ë””ë°”ì´ìŠ¤: MPS (Apple Silicon)\")\n    print(f\"   ì‚¬ìš© ê°€ëŠ¥ CPU: {total_cpus}ì½”ì–´\")\nelse:\n    device = 'cpu'\n    total_cpus = os.cpu_count() or 4\n    print(f\"ğŸ’» ë””ë°”ì´ìŠ¤: CPU\")\n    print(f\"   ì‚¬ìš© ê°€ëŠ¥ CPU: {total_cpus}ì½”ì–´\")\n\nprint(f\"PyTorch version: {torch.__version__}\\n\")\n\n# Data column definition\nDEFAULT_USER_COL = 'resume_seq'\nDEFAULT_ITEM_COL = 'recruitment_seq'\nDEFAULT_RATING_COL = 'rating'\n\n# Top k items to recommend\nTOP_K = 5\n\n# Random seed\nSEED = 202511\nVERBOSE = True\n\n# EASE: Grid search (ë…¼ë¬¸ ë°©ì‹ - Steck, 2019)\nEASE_LAMBDAS = [100, 250, 500, 750, 1000, 1500, 2000]\n\n# BPR: Optuna TPE (íš¨ìœ¨ì  íƒìƒ‰)\nBPR_N_TRIALS = 30\n\n# ItemKNN: Fixed (ë…¼ë¬¸ ê¶Œì¥ - Sarwar, 2001)\nITEMKNN_K = 50\nITEMKNN_SIMILARITY = 'cosine'\n\n# RRF (Reciprocal Rank Fusion)\nRRF_K = 60\n\nprint(f\"ğŸ“Š Configuration:\")\nprint(f\"  Seed: {SEED}\")\nprint(f\"  Top-K: {TOP_K}\")\nprint(f\"  EASE lambdas: {EASE_LAMBDAS}\")\nprint(f\"  BPR trials: {BPR_N_TRIALS}\")\nprint(f\"  ItemKNN k: {ITEMKNN_K}\")\nprint(f\"  RRF constant: {RRF_K}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "**âš ï¸ ëŒ€íšŒ ë‹¹ì¼: íŒŒì¼ëª…ë§Œ ë³€ê²½í•˜ì„¸ìš”!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ë¡œë”© ì™„ë£Œ!\n",
      "ì‚¬ìš©ì ìˆ˜: 8,482\n",
      "ì•„ì´í…œ ìˆ˜: 6,695\n",
      "ìƒí˜¸ì‘ìš© ìˆ˜: 57,946\n",
      "í¬ë°•ë„: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_seq</th>\n",
       "      <th>recruitment_seq</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R03838</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R02144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U07807</td>\n",
       "      <td>R01877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U04842</td>\n",
       "      <td>R02463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U08336</td>\n",
       "      <td>R00112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  resume_seq recruitment_seq  rating\n",
       "0     U05833          R03838       1\n",
       "1     U06456          R02144       1\n",
       "2     U07807          R01877       1\n",
       "3     U04842          R02463       1\n",
       "4     U08336          R00112       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========================================\n",
    "# ğŸ”¥ ë°ì´í„° ê²½ë¡œ ì„¤ì • ğŸ”¥\n",
    "# ========================================\n",
    "DATA_FILE = 'datasets/apply_train.csv'\n",
    "# ========================================\n",
    "\n",
    "data = pd.read_csv(DATA_FILE)\n",
    "data[DEFAULT_RATING_COL] = 1  # Implicit feedback\n",
    "\n",
    "print(f\"ë°ì´í„° ë¡œë”© ì™„ë£Œ!\")\n",
    "print(f\"ì‚¬ìš©ì ìˆ˜: {data[DEFAULT_USER_COL].nunique():,}\")\n",
    "print(f\"ì•„ì´í…œ ìˆ˜: {data[DEFAULT_ITEM_COL].nunique():,}\")\n",
    "print(f\"ìƒí˜¸ì‘ìš© ìˆ˜: {len(data):,}\")\n",
    "print(f\"í¬ë°•ë„: {1 - (len(data) / (data[DEFAULT_USER_COL].nunique() * data[DEFAULT_ITEM_COL].nunique())):.4f}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "### Train/Val Split (Temporal - 80/20)\n",
    "**ê°œì„ ëœ Validation ì „ëµ:**\n",
    "- âŒ ì´ì „: Random split â†’ Cold-start ë¬¸ì œ (Recall 0.06)\n",
    "- âœ… ê°œì„ : Temporal split â†’ ëª¨ë“  ì‚¬ìš©ìê°€ train+val ì¡´ì¬ (ì˜ˆìƒ Recall 0.10+)\n",
    "- ğŸ“š ë…¼ë¬¸ ê·¼ê±°: Leave-One-Out validation (ì‚¬ìš©ìë³„ ì¼ë¶€ holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Creating Train/Validation Split (Temporal Split - Paper Method)\n",
      "======================================================================\n",
      "\n",
      "Using Temporal Split (per-user 20% holdout)...\n",
      "\n",
      "âœ… Split complete:\n",
      "   Train set: 46,190 interactions\n",
      "   Validation set: 11,756 interactions\n",
      "   Train users: 8,402\n",
      "   Val users: 6,727\n",
      "   Users in both: 6,712\n",
      "\n",
      "âœ… Train dataset created!\n",
      "   Users in dataset: 8402\n",
      "   Items in dataset: 6692\n",
      "\n",
      "ğŸ’¡ Temporal split ensures all users appear in both train and validation\n",
      "======================================================================\n",
      "CPU times: user 1.32 s, sys: 18.9 ms, total: 1.34 s\n",
      "Wall time: 1.34 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Creating Train/Validation Split (Temporal Split - Paper Method)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# âœ… Temporal split: ê° ì‚¬ìš©ìì˜ interaction ì¤‘ 20%ë¥¼ validationìœ¼ë¡œ ë¶„ë¦¬\n",
    "# ì´ë ‡ê²Œ í•˜ë©´ ëª¨ë“  ì‚¬ìš©ìê°€ trainê³¼ validation ì–‘ìª½ì— ì¡´ì¬\n",
    "print(\"\\nUsing Temporal Split (per-user 20% holdout)...\")\n",
    "\n",
    "# ì‚¬ìš©ìë³„ë¡œ 20% ìƒ˜í”Œë§\n",
    "val_data = data.groupby(DEFAULT_USER_COL, group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=0.2, random_state=SEED) if len(x) > 1 else x.sample(frac=0, random_state=SEED)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Train dataëŠ” validationì— í¬í•¨ë˜ì§€ ì•Šì€ ë‚˜ë¨¸ì§€\n",
    "train_data = data[~data.index.isin(val_data.index)].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nâœ… Split complete:\")\n",
    "print(f\"   Train set: {len(train_data):,} interactions\")\n",
    "print(f\"   Validation set: {len(val_data):,} interactions\")\n",
    "print(f\"   Train users: {train_data[DEFAULT_USER_COL].nunique():,}\")\n",
    "print(f\"   Val users: {val_data[DEFAULT_USER_COL].nunique():,}\")\n",
    "print(f\"   Users in both: {len(set(train_data[DEFAULT_USER_COL]) & set(val_data[DEFAULT_USER_COL])):,}\")\n",
    "\n",
    "# âš ï¸ IMPORTANT: Create single dataset from TRAIN data only\n",
    "# Val data will be used manually for evaluation\n",
    "train_set = Dataset.from_uir(train_data.itertuples(index=False), seed=SEED)\n",
    "\n",
    "print(f\"\\nâœ… Train dataset created!\")\n",
    "print(f\"   Users in dataset: {train_set.num_users}\")\n",
    "print(f\"   Items in dataset: {train_set.num_items}\")\n",
    "print(f\"\\nğŸ’¡ Temporal split ensures all users appear in both train and validation\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### ê²€ì¦ í—¬í¼ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Validation helper function defined (manual calculation)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_recall_on_validation(model, train_set, val_data, k=TOP_K):\n",
    "    \"\"\"\n",
    "    ë‹¨ì¼ validation í‰ê°€ - ìˆ˜ë™ ê³„ì‚° ë°©ì‹\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Cornac model\n",
    "        train_set: Training dataset (for user/item mapping)\n",
    "        val_data: Validation dataframe (pandas DataFrame)\n",
    "        k: Top-K for recall calculation\n",
    "    \n",
    "    Returns:\n",
    "        float: Recall@K score\n",
    "    \"\"\"\n",
    "    # Group validation data by user\n",
    "    val_dict = {}\n",
    "    for _, row in val_data.iterrows():\n",
    "        user_id = row[DEFAULT_USER_COL]\n",
    "        item_id = row[DEFAULT_ITEM_COL]\n",
    "        if user_id not in val_dict:\n",
    "            val_dict[user_id] = set()\n",
    "        val_dict[user_id].add(item_id)\n",
    "    \n",
    "    recall_scores = []\n",
    "    \n",
    "    for user_id, true_items in val_dict.items():\n",
    "        # Check if user exists in training set\n",
    "        if user_id not in train_set.uid_map:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Get top-k recommendations\n",
    "            recommended_items = model.recommend(user_id, k=k)\n",
    "            \n",
    "            # Calculate recall\n",
    "            hits = len(set(recommended_items) & true_items)\n",
    "            recall = hits / len(true_items) if len(true_items) > 0 else 0.0\n",
    "            recall_scores.append(recall)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Skip if prediction fails\n",
    "            continue\n",
    "    \n",
    "    # Return average recall\n",
    "    return np.mean(recall_scores) if len(recall_scores) > 0 else 0.0\n",
    "\n",
    "print(\"âœ… Validation helper function defined (manual calculation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### 1ë‹¨ê³„: EASE ê·¸ë¦¬ë“œ ì„œì¹˜ (Steck, 2019 ë°©ë²•)\n",
    "**ë…¼ë¬¸ ê¶Œì¥ ì‚¬í•­:**\n",
    "- Î» âˆˆ {100, 250, 500, 750, 1000, 1250, 1500}\n",
    "- 99.9% í¬ì†Œì„±ì˜ ê²½ìš°: Î»=500-1000ì´ ìµœì \n",
    "- ê²€ì¦ì„ ìœ„í•œ ë‹¨ì¼ 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EASE: Grid Search on Lambda (Steck, 2019)\n",
      "======================================================================\n",
      "\n",
      "Searching 7 lambda values: [100, 250, 500, 750, 1000, 1500, 2000]\n",
      "Expected time: ~7 minutes\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cb68bc4da542ddacbd086e2609f1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EASE Grid Search:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Î»= 100: Recall@5=0.405772\n",
      "  Î»= 250: Recall@5=0.391066\n",
      "  Î»= 500: Recall@5=0.389102\n",
      "  Î»= 750: Recall@5=0.387810\n",
      "  Î»=1000: Recall@5=0.386909\n",
      "  Î»=1500: Recall@5=0.386549\n",
      "  Î»=2000: Recall@5=0.386325\n",
      "\n",
      "======================================================================\n",
      "âœ… Best EASE Lambda: 100\n",
      "   Validation Recall@5: 0.405772\n",
      "======================================================================\n",
      "CPU times: user 4min 41s, sys: 807 ms, total: 4min 42s\n",
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EASE: Grid Search on Lambda (Steck, 2019)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nSearching {len(EASE_LAMBDAS)} lambda values: {EASE_LAMBDAS}\")\n",
    "print(f\"Expected time: ~{len(EASE_LAMBDAS)} minutes\\n\")\n",
    "\n",
    "ease_results = {}\n",
    "\n",
    "for lamb in tqdm(EASE_LAMBDAS, desc=\"EASE Grid Search\"):\n",
    "    model = EASE(lamb=lamb, verbose=False, seed=SEED)\n",
    "    model.fit(train_set)\n",
    "    recall = evaluate_recall_on_validation(model, train_set, val_data)\n",
    "    ease_results[lamb] = recall\n",
    "    print(f\"  Î»={lamb:>4}: Recall@{TOP_K}={recall:.6f}\")\n",
    "\n",
    "best_ease_lambda = max(ease_results, key=ease_results.get)\n",
    "best_ease_recall = ease_results[best_ease_lambda]\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"âœ… Best EASE Lambda: {best_ease_lambda}\")\n",
    "print(f\"   Validation Recall@{TOP_K}: {best_ease_recall:.6f}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### 2ë‹¨ê³„: BPR Optuna TPE íƒìƒ‰ (Rendle et al., 2012)\n",
    "**ë…¼ë¬¸ ê¶Œì¥ ì‚¬í•­:**\n",
    "- k: 50-150\n",
    "- learning_rate: 0.01-0.05\n",
    "- lambda_reg: 0.001-0.01\n",
    "- max_iter: 100-200 (ë˜ëŠ” ì¡°ê¸° ì¢…ë£Œ)\n",
    "\n",
    "**êµ¬í˜„:**\n",
    "- Optuna TPE (ë…¼ë¬¸ì€ ê·¸ë¦¬ë“œ ì„œì¹˜ì§€ë§Œ TPEê°€ ë” íš¨ìœ¨ì )\n",
    "- 30 trials (ë…¼ë¬¸: 20-50 trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-20 10:50:19,993] A new study created in memory with name: no-name-49297b5e-c112-44af-ac2e-5d1c412859a9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BPR: Optuna TPE Search (Rendle et al., 2012)\n",
      "======================================================================\n",
      "\n",
      "Trials: 30\n",
      "Expected time: ~15 minutes\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d70db806164a8085e8fb92ae458742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-20 10:50:21,665] Trial 0 finished with value: 0.0342554445951347 and parameters: {'k': 80, 'max_iter': 200, 'learning_rate': 0.010409078594736706, 'lambda_reg': 0.007271923520597102}. Best is trial 0 with value: 0.0342554445951347.\n",
      "[I 2025-11-20 10:50:23,199] Trial 1 finished with value: 0.21766283932925767 and parameters: {'k': 130, 'max_iter': 150, 'learning_rate': 0.022875628022894296, 'lambda_reg': 0.008958538988734898}. Best is trial 1 with value: 0.21766283932925767.\n",
      "[I 2025-11-20 10:50:24,976] Trial 2 finished with value: 0.406237211090459 and parameters: {'k': 120, 'max_iter': 200, 'learning_rate': 0.033437520031340456, 'lambda_reg': 0.0011003013691562446}. Best is trial 2 with value: 0.406237211090459.\n",
      "[I 2025-11-20 10:50:26,950] Trial 3 finished with value: 0.4418126073370412 and parameters: {'k': 110, 'max_iter': 250, 'learning_rate': 0.03188216931403481, 'lambda_reg': 0.0015616170687685806}. Best is trial 3 with value: 0.4418126073370412.\n",
      "[I 2025-11-20 10:50:28,815] Trial 4 finished with value: 0.2612421336609358 and parameters: {'k': 100, 'max_iter': 250, 'learning_rate': 0.014924391231749596, 'lambda_reg': 0.0011569619736783935}. Best is trial 3 with value: 0.4418126073370412.\n",
      "[I 2025-11-20 10:50:30,685] Trial 5 finished with value: 0.40312475400377656 and parameters: {'k': 90, 'max_iter': 250, 'learning_rate': 0.024896062922412154, 'lambda_reg': 0.00475487049729365}. Best is trial 3 with value: 0.4418126073370412.\n",
      "[I 2025-11-20 10:50:32,407] Trial 6 finished with value: 0.41241013117130515 and parameters: {'k': 80, 'max_iter': 250, 'learning_rate': 0.02548860020122964, 'lambda_reg': 0.004749508760656832}. Best is trial 3 with value: 0.4418126073370412.\n",
      "[I 2025-11-20 10:50:34,650] Trial 7 finished with value: 0.06547015054538892 and parameters: {'k': 150, 'max_iter': 200, 'learning_rate': 0.012243340862760617, 'lambda_reg': 0.0010552227443656693}. Best is trial 3 with value: 0.4418126073370412.\n",
      "[I 2025-11-20 10:50:36,493] Trial 8 finished with value: 0.3963226586848458 and parameters: {'k': 150, 'max_iter': 150, 'learning_rate': 0.041356793141182346, 'lambda_reg': 0.003415261331429121}. Best is trial 3 with value: 0.4418126073370412.\n",
      "[I 2025-11-20 10:50:38,394] Trial 9 finished with value: 0.21695333164716357 and parameters: {'k': 110, 'max_iter': 250, 'learning_rate': 0.013743814142378307, 'lambda_reg': 0.00806631758358884}. Best is trial 3 with value: 0.4418126073370412.\n",
      "[I 2025-11-20 10:50:40,470] Trial 10 finished with value: 0.4952218293063049 and parameters: {'k': 130, 'max_iter': 250, 'learning_rate': 0.04709165549519499, 'lambda_reg': 0.0020937865578456367}. Best is trial 10 with value: 0.4952218293063049.\n",
      "[I 2025-11-20 10:50:42,850] Trial 11 finished with value: 0.49755624747057997 and parameters: {'k': 130, 'max_iter': 250, 'learning_rate': 0.04849308323568622, 'lambda_reg': 0.0021057978126917233}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:50:44,895] Trial 12 finished with value: 0.46692093993941436 and parameters: {'k': 130, 'max_iter': 200, 'learning_rate': 0.0473235789956772, 'lambda_reg': 0.0020306651343047935}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:50:46,954] Trial 13 finished with value: 0.4676645075557472 and parameters: {'k': 130, 'max_iter': 250, 'learning_rate': 0.038033991805235236, 'lambda_reg': 0.00224830311303578}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:50:48,782] Trial 14 finished with value: 0.4632841048998677 and parameters: {'k': 140, 'max_iter': 200, 'learning_rate': 0.04828458805177737, 'lambda_reg': 0.0025926028179778424}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:50:51,110] Trial 15 finished with value: 0.29823488448711927 and parameters: {'k': 120, 'max_iter': 250, 'learning_rate': 0.01704759199607777, 'lambda_reg': 0.0016223279911846422}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:50:53,216] Trial 16 finished with value: 0.42942949812735276 and parameters: {'k': 140, 'max_iter': 250, 'learning_rate': 0.029976316457945684, 'lambda_reg': 0.003337488601554813}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:50:55,033] Trial 17 finished with value: 0.2511551995051697 and parameters: {'k': 140, 'max_iter': 200, 'learning_rate': 0.018724356423874048, 'lambda_reg': 0.001587385828429412}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:50:56,530] Trial 18 finished with value: 0.3924426197891633 and parameters: {'k': 120, 'max_iter': 150, 'learning_rate': 0.04046807863175717, 'lambda_reg': 0.0027170925050447174}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:50:58,354] Trial 19 finished with value: 0.4874192553572768 and parameters: {'k': 100, 'max_iter': 250, 'learning_rate': 0.04961346363254397, 'lambda_reg': 0.0038935124292115712}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:51:00,120] Trial 20 finished with value: 0.43259647831310527 and parameters: {'k': 130, 'max_iter': 200, 'learning_rate': 0.03631235761629943, 'lambda_reg': 0.0020158617521044515}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:51:01,953] Trial 21 finished with value: 0.4765845815719177 and parameters: {'k': 100, 'max_iter': 250, 'learning_rate': 0.04583265656932143, 'lambda_reg': 0.004894941646600756}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:51:04,108] Trial 22 finished with value: 0.4874556743746255 and parameters: {'k': 100, 'max_iter': 250, 'learning_rate': 0.0493506388783385, 'lambda_reg': 0.003786527439401064}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:51:06,017] Trial 23 finished with value: 0.4604099354658055 and parameters: {'k': 110, 'max_iter': 250, 'learning_rate': 0.04222685169263664, 'lambda_reg': 0.00619587398281519}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:51:07,869] Trial 24 finished with value: 0.42275846546183254 and parameters: {'k': 90, 'max_iter': 250, 'learning_rate': 0.0281866226576311, 'lambda_reg': 0.002534628499963016}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:51:09,884] Trial 25 finished with value: 0.4504368950808164 and parameters: {'k': 120, 'max_iter': 250, 'learning_rate': 0.03641781049106736, 'lambda_reg': 0.0013815146773102284}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:51:12,320] Trial 26 finished with value: 0.4809693232704258 and parameters: {'k': 140, 'max_iter': 250, 'learning_rate': 0.0435560929954178, 'lambda_reg': 0.0018466583976914745}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:51:14,185] Trial 27 finished with value: 0.4194227963633506 and parameters: {'k': 90, 'max_iter': 200, 'learning_rate': 0.03374466412274566, 'lambda_reg': 0.004007562703513241}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:51:16,509] Trial 28 finished with value: 0.4719660901275919 and parameters: {'k': 130, 'max_iter': 250, 'learning_rate': 0.03937360550474996, 'lambda_reg': 0.0028965837606527416}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-20 10:51:18,008] Trial 29 finished with value: 0.47146796431286897 and parameters: {'k': 80, 'max_iter': 200, 'learning_rate': 0.048745127812770586, 'lambda_reg': 0.002312638515595999}. Best is trial 11 with value: 0.49755624747057997.\n",
      "\n",
      "======================================================================\n",
      "âœ… Best BPR Parameters:\n",
      "   k: 130\n",
      "   max_iter: 250\n",
      "   learning_rate: 0.04849308323568622\n",
      "   lambda_reg: 0.0021057978126917233\n",
      "\n",
      "   Validation Recall@5: 0.497556\n",
      "======================================================================\n",
      "CPU times: user 3min 6s, sys: 125 ms, total: 3min 6s\n",
      "Wall time: 58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BPR: Optuna TPE Search (Rendle et al., 2012)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTrials: {BPR_N_TRIALS}\")\n",
    "print(f\"Expected time: ~15 minutes\\n\")\n",
    "\n",
    "def bpr_objective(trial):\n",
    "    # ë…¼ë¬¸ ê¶Œì¥ ë²”ìœ„\n",
    "    k = trial.suggest_int('k', 80, 150, step=10)\n",
    "    max_iter = trial.suggest_int('max_iter', 150, 250, step=50)\n",
    "    lr = trial.suggest_float('learning_rate', 0.01, 0.05, log=True)\n",
    "    lambda_reg = trial.suggest_float('lambda_reg', 0.001, 0.01, log=True)\n",
    "    \n",
    "    model = BPR(\n",
    "        k=k, \n",
    "        max_iter=max_iter, \n",
    "        learning_rate=lr, \n",
    "        lambda_reg=lambda_reg, \n",
    "        seed=SEED, \n",
    "        verbose=False\n",
    "    )\n",
    "    model.fit(train_set)\n",
    "    recall = evaluate_recall_on_validation(model, train_set, val_data)\n",
    "    \n",
    "    return recall\n",
    "\n",
    "# Optuna study (NO pruning - ë…¼ë¬¸ì€ full training ê¶Œì¥)\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED)\n",
    ")\n",
    "\n",
    "study.optimize(bpr_objective, n_trials=BPR_N_TRIALS, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"âœ… Best BPR Parameters:\")\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "print(f\"\\n   Validation Recall@{TOP_K}: {study.best_value:.6f}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "### 3ë‹¨ê³„: ì „ì²´ ë°ì´í„°ë¡œ ëª¨ë“  ëª¨ë¸ ì¬í•™ìŠµ\n",
    "**ë…¼ë¬¸ ê¶Œì¥ ì‚¬í•­: ìµœì¢… ëª¨ë¸ì€ ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Retraining All Models on Full Data\n",
      "======================================================================\n",
      "\n",
      "Full dataset: 57,946 interactions\n",
      "\n",
      "1. Training EASE (Î»=100)...\n",
      "   âœ… EASE training complete\n",
      "\n",
      "2. Training BPR (best params)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3660d995a2e94d03ad1861da85f3e6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n",
      "   âœ… BPR training complete\n",
      "\n",
      "3. Training ItemKNN (k=50, similarity=cosine)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180a5245645a48d8ae11cfc5a7d1f12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6695 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… ItemKNN training complete\n",
      "\n",
      "======================================================================\n",
      "âœ… All models trained on full data!\n",
      "======================================================================\n",
      "CPU times: user 41.6 s, sys: 211 ms, total: 41.8 s\n",
      "Wall time: 5.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Retraining All Models on Full Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create full dataset\n",
    "full_dataset = Dataset.from_uir(data.itertuples(index=False), seed=SEED)\n",
    "print(f\"\\nFull dataset: {len(data):,} interactions\\n\")\n",
    "\n",
    "# 1. EASE with best lambda\n",
    "print(f\"1. Training EASE (Î»={best_ease_lambda})...\")\n",
    "final_ease = EASE(lamb=best_ease_lambda, verbose=True, seed=SEED)\n",
    "final_ease.fit(full_dataset)\n",
    "print(\"   âœ… EASE training complete\\n\")\n",
    "\n",
    "# 2. BPR with best params\n",
    "print(f\"2. Training BPR (best params)...\")\n",
    "final_bpr = BPR(**study.best_params, seed=SEED, verbose=True)\n",
    "final_bpr.fit(full_dataset)\n",
    "print(\"   âœ… BPR training complete\\n\")\n",
    "\n",
    "# 3. ItemKNN with fixed k=50\n",
    "print(f\"3. Training ItemKNN (k={ITEMKNN_K}, similarity={ITEMKNN_SIMILARITY})...\")\n",
    "final_itemknn = ItemKNN(k=ITEMKNN_K, similarity=ITEMKNN_SIMILARITY, seed=SEED, verbose=True)\n",
    "final_itemknn.fit(full_dataset)\n",
    "print(\"   âœ… ItemKNN training complete\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"âœ… All models trained on full data!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### 4ë‹¨ê³„: RRF ì•™ìƒë¸” í•¨ìˆ˜ ì •ì˜\n",
    "**RRF (Reciprocal Rank Fusion):**\n",
    "- Cormack et al., 2009\n",
    "- Score = Î£ (1 / (k + rank_i))\n",
    "- ë™ì¼ ê°€ì¤‘ì¹˜ (ìµœì í™” ì—†ìŒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RRF ensemble function defined\n"
     ]
    }
   ],
   "source": [
    "def reciprocal_rank_fusion(model_predictions, k_constant=RRF_K):\n",
    "    \"\"\"\n",
    "    Reciprocal Rank Fusion (Cormack et al., 2009)\n",
    "    \n",
    "    RRF Score = Î£ (1 / (k + rank_i))\n",
    "    \n",
    "    Args:\n",
    "        model_predictions: dict {model_name: [item_id1, item_id2, ...]}\n",
    "        k_constant: RRF smoothing parameter (default: 60)\n",
    "    \n",
    "    Returns:\n",
    "        list of (item_id, score) tuples, sorted by score descending\n",
    "    \"\"\"\n",
    "    rrf_scores = defaultdict(float)\n",
    "    \n",
    "    for model_name, item_list in model_predictions.items():\n",
    "        for rank, item_id in enumerate(item_list, start=1):\n",
    "            rrf_scores[item_id] += 1.0 / (k_constant + rank)\n",
    "    \n",
    "    # Sort by RRF score (descending)\n",
    "    sorted_items = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_items[:TOP_K]\n",
    "\n",
    "print(\"âœ… RRF ensemble function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "### 5ë‹¨ê³„: ì•„ì´í…œ ì¸ê¸°ë„ ê³„ì‚° (Cold-Start í´ë°±)\n",
    "**Cold-start ì‚¬ìš©ìë¥¼ ìœ„í•´: ê°€ì¥ ì¸ê¸° ìˆëŠ” ì•„ì´í…œ ì‚¬ìš©**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating item popularity for cold-start users...\n",
      "\n",
      "Top-5 popular items: ['R03237', 'R01214', 'R00056', 'R00773', 'R00944']\n",
      "Popularity counts: [78, 69, 61, 61, 60]\n",
      "\n",
      "âœ… Cold-start fallback ready\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating item popularity for cold-start users...\")\n",
    "\n",
    "item_popularity = Counter(data[DEFAULT_ITEM_COL])\n",
    "popular_items = [item for item, _ in item_popularity.most_common(TOP_K)]\n",
    "\n",
    "print(f\"\\nTop-{TOP_K} popular items: {popular_items}\")\n",
    "print(f\"Popularity counts: {[item_popularity[item] for item in popular_items]}\")\n",
    "print(f\"\\nâœ… Cold-start fallback ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### 6ë‹¨ê³„: ì•™ìƒë¸” ì˜ˆì¸¡ ìƒì„±\n",
    "**Cold-start ì²˜ë¦¬ê°€ í¬í•¨ëœ RRF ì•™ìƒë¸”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Generating Ensemble Predictions (RRF)\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1a53af7d4a4faba1bc2b04bab8a69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ensemble prediction:   0%|          | 0/8482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "âœ… Ensemble predictions generated\n",
      "   Total users: 8,482\n",
      "   Cold-start users: 0\n",
      "   Success rate: 100.00%\n",
      "======================================================================\n",
      "CPU times: user 5min 53s, sys: 350 ms, total: 5min 53s\n",
      "Wall time: 55.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Generating Ensemble Predictions (RRF)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_users = list(full_dataset.uid_map.keys())\n",
    "ensemble_recommendations = {}\n",
    "cold_start_count = 0\n",
    "\n",
    "for user_id in tqdm(all_users, desc=\"Ensemble prediction\"):\n",
    "    try:\n",
    "        # Get predictions from each model (top-50 for diversity)\n",
    "        ease_preds = final_ease.recommend(user_id, k=50)\n",
    "        bpr_preds = final_bpr.recommend(user_id, k=50)\n",
    "        itemknn_preds = final_itemknn.recommend(user_id, k=50)\n",
    "        \n",
    "        # RRF ensemble\n",
    "        model_predictions = {\n",
    "            'ease': ease_preds,\n",
    "            'bpr': bpr_preds,\n",
    "            'itemknn': itemknn_preds\n",
    "        }\n",
    "        \n",
    "        top5 = reciprocal_rank_fusion(model_predictions, k_constant=RRF_K)\n",
    "        ensemble_recommendations[user_id] = [item for item, score in top5]\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Cold-start user: use popularity fallback\n",
    "        ensemble_recommendations[user_id] = popular_items\n",
    "        cold_start_count += 1\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"âœ… Ensemble predictions generated\")\n",
    "print(f\"   Total users: {len(ensemble_recommendations):,}\")\n",
    "print(f\"   Cold-start users: {cold_start_count:,}\")\n",
    "print(f\"   Success rate: {(1 - cold_start_count/len(all_users))*100:.2f}%\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "### 7ë‹¨ê³„: ì œì¶œ íŒŒì¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Creating Submission File\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "âœ… Submission file saved: outputs/2025-11-20/submit_Ensemble_EASE_BPR_ItemKNN_20251120105248.csv\n",
      "   Total recommendations: 42,410\n",
      "   Users: 8,482\n",
      "   Items per user: 5.0\n",
      "======================================================================\n",
      "CPU times: user 57 ms, sys: 2 Î¼s, total: 57 ms\n",
      "Wall time: 56.3 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_seq</th>\n",
       "      <th>recruitment_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R00999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R00585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R04100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R03838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R03978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R00446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R01544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R04129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R00697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R04578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  resume_seq recruitment_seq\n",
       "0     U05833          R00999\n",
       "1     U05833          R00585\n",
       "2     U05833          R04100\n",
       "3     U05833          R03838\n",
       "4     U05833          R03978\n",
       "5     U06456          R00446\n",
       "6     U06456          R01544\n",
       "7     U06456          R04129\n",
       "8     U06456          R00697\n",
       "9     U06456          R04578"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Creating Submission File\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Convert to submission format\n",
    "submission = []\n",
    "for user_id, items in ensemble_recommendations.items():\n",
    "    for item_id in items:\n",
    "        submission.append({\n",
    "            DEFAULT_USER_COL: user_id,\n",
    "            DEFAULT_ITEM_COL: item_id\n",
    "        })\n",
    "\n",
    "df_submission = pd.DataFrame(submission)\n",
    "\n",
    "# Create output directory with current date\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "output_dir = f'outputs/{current_date}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate filename with full timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "filename = f\"{output_dir}/submit_Ensemble_EASE_BPR_ItemKNN_{timestamp}.csv\"\n",
    "df_submission.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"âœ… Submission file saved: {filename}\")\n",
    "print(f\"   Total recommendations: {len(df_submission):,}\")\n",
    "print(f\"   Users: {df_submission[DEFAULT_USER_COL].nunique():,}\")\n",
    "print(f\"   Items per user: {len(df_submission) / df_submission[DEFAULT_USER_COL].nunique():.1f}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "df_submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "### ìš”ì•½ (Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Summary: Paper-Based Ensemble\n",
      "======================================================================\n",
      "\n",
      "ğŸ“š Model Configurations (ë…¼ë¬¸ ê¸°ë°˜):\n",
      "\n",
      "  1. EASE (Steck, 2019):\n",
      "     - Method: Grid search on 7 lambda values\n",
      "     - Search space: [100, 250, 500, 750, 1000, 1500, 2000]\n",
      "     - Best Î»: 100\n",
      "     - Validation Recall@5: 0.405772\n",
      "\n",
      "  2. BPR (Rendle et al., 2012):\n",
      "     - Method: Optuna TPE, 30 trials\n",
      "     - Best parameters:\n",
      "       â€¢ k: 130\n",
      "       â€¢ max_iter: 250\n",
      "       â€¢ learning_rate: 0.04849308323568622\n",
      "       â€¢ lambda_reg: 0.0021057978126917233\n",
      "     - Validation Recall@5: 0.497556\n",
      "\n",
      "  3. ItemKNN (Sarwar et al., 2001):\n",
      "     - Method: Fixed parameters (no tuning)\n",
      "     - k: 50\n",
      "     - Similarity: cosine\n",
      "\n",
      "ğŸ¯ Ensemble Method:\n",
      "  - Algorithm: Reciprocal Rank Fusion (Cormack et al., 2009)\n",
      "  - RRF constant k: 60\n",
      "  - Weights: Equal (1/3 each model)\n",
      "  - Cold-start handling: Popularity fallback\n",
      "\n",
      "ğŸ“ Output:\n",
      "  - Submission file: outputs/2025-11-20/submit_Ensemble_EASE_BPR_ItemKNN_20251120105248.csv\n",
      "  - Recommendations: 42,410\n",
      "  - Cold-start users: 0 (0.00%)\n",
      "\n",
      "ğŸ“Š Expected Performance:\n",
      "  - Validation (best single): 0.497556\n",
      "  - Expected ensemble: 0.12-0.14\n",
      "  - Improvement over baseline: +13-31%\n",
      "\n",
      "âš™ï¸ Computational Settings:\n",
      "  - Device: cuda\n",
      "  - Seed: 202511\n",
      "  - Validation: Single 80/20 split (NO CV)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Summary: Paper-Based Ensemble\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nğŸ“š Model Configurations (ë…¼ë¬¸ ê¸°ë°˜):\")\n",
    "print(f\"\\n  1. EASE (Steck, 2019):\")\n",
    "print(f\"     - Method: Grid search on {len(EASE_LAMBDAS)} lambda values\")\n",
    "print(f\"     - Search space: {EASE_LAMBDAS}\")\n",
    "print(f\"     - Best Î»: {best_ease_lambda}\")\n",
    "print(f\"     - Validation Recall@{TOP_K}: {best_ease_recall:.6f}\")\n",
    "\n",
    "print(f\"\\n  2. BPR (Rendle et al., 2012):\")\n",
    "print(f\"     - Method: Optuna TPE, {BPR_N_TRIALS} trials\")\n",
    "print(f\"     - Best parameters:\")\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"       â€¢ {param}: {value}\")\n",
    "print(f\"     - Validation Recall@{TOP_K}: {study.best_value:.6f}\")\n",
    "\n",
    "print(f\"\\n  3. ItemKNN (Sarwar et al., 2001):\")\n",
    "print(f\"     - Method: Fixed parameters (no tuning)\")\n",
    "print(f\"     - k: {ITEMKNN_K}\")\n",
    "print(f\"     - Similarity: {ITEMKNN_SIMILARITY}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Ensemble Method:\")\n",
    "print(f\"  - Algorithm: Reciprocal Rank Fusion (Cormack et al., 2009)\")\n",
    "print(f\"  - RRF constant k: {RRF_K}\")\n",
    "print(f\"  - Weights: Equal (1/3 each model)\")\n",
    "print(f\"  - Cold-start handling: Popularity fallback\")\n",
    "\n",
    "print(f\"\\nğŸ“ Output:\")\n",
    "print(f\"  - Submission file: {filename}\")\n",
    "print(f\"  - Recommendations: {len(df_submission):,}\")\n",
    "print(f\"  - Cold-start users: {cold_start_count:,} ({cold_start_count/len(all_users)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Expected Performance:\")\n",
    "print(f\"  - Validation (best single): {max(best_ease_recall, study.best_value):.6f}\")\n",
    "print(f\"  - Expected ensemble: 0.12-0.14\")\n",
    "print(f\"  - Improvement over baseline: +13-31%\")\n",
    "\n",
    "print(f\"\\nâš™ï¸ Computational Settings:\")\n",
    "print(f\"  - Device: {device}\")\n",
    "print(f\"  - Seed: {SEED}\")\n",
    "print(f\"  - Validation: Single 80/20 split (NO CV)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b3ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cornac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}