{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# BPR (Bayesian Personalized Ranking) - Ï∂îÏ≤ú ÏãúÏä§ÌÖú\n",
    "\n",
    "**ÎÖºÎ¨∏**: Rendle et al., 2012 - \"BPR: Bayesian Personalized Ranking from Implicit Feedback\"  \n",
    "**Conference**: UAI 2012\n",
    "\n",
    "## üìö Î™®Îç∏ ÏÑ§Î™Ö\n",
    "\n",
    "### ÌïµÏã¨ ÏïåÍ≥†Î¶¨Ï¶ò\n",
    "- **Pairwise ranking** Ï†ëÍ∑ºÎ≤ï - ÏïÑÏù¥ÌÖú Í∞Ñ ÏÉÅÎåÄÏ†Å ÏàúÏúÑ ÏµúÏ†ÅÌôî\n",
    "- **ÏïîÎ¨µÏ†Å ÌîºÎìúÎ∞±** Ï†ÑÏö© - ÌÅ¥Î¶≠/Íµ¨Îß§ Ïù¥Î†•ÎßåÏúºÎ°ú ÌïôÏäµ Í∞ÄÎä•\n",
    "- **Î∂ÄÏ†ï ÏÉòÌîåÎßÅ** ÏûêÎèô Ï≤òÎ¶¨ - Í∏çÏ†ï(ÏÉÅÌò∏ÏûëÏö© O)Í≥º Î∂ÄÏ†ï(ÏÉÅÌò∏ÏûëÏö© X) Ïåç ÌïôÏäµ\n",
    "- **Matrix Factorization** Í∏∞Î∞ò - ÏÇ¨Ïö©Ïûê/ÏïÑÏù¥ÌÖúÏùÑ Ïû†Ïû¨ Î≤°ÌÑ∞Î°ú ÌëúÌòÑ\n",
    "\n",
    "## üéØ ÌïµÏã¨ Ï†ÑÎûµ\n",
    "\n",
    "### ÌäúÎãù Ï†ÑÎûµ (ÎÖºÎ¨∏ Í∏∞Î∞ò)\n",
    "1. **Validation**: 80/20 temporal split (ÏãúÍ∞Ñ ÏàúÏÑú Í≥†Î†§)\n",
    "2. **Method**: Optuna TPE (Bayesian optimization)\n",
    "3. **ÌïµÏã¨ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞**:\n",
    "   - **k** (latent factors): 80-150 - Ïû†Ïû¨ ÏöîÏù∏ Ï∞®ÏõêÏàò\n",
    "   - **learning_rate**: 0.01-0.05 - SGD ÌïôÏäµÎ•†\n",
    "   - **lambda_reg**: 0.001-0.01 - L2 Ï†ïÍ∑úÌôî Í∞ïÎèÑ\n",
    "   - **max_iter**: 150-250 - ÌïôÏäµ Î∞òÎ≥µ ÌöüÏàò\n",
    "4. **Budget**: 20-50 trials (30 trials Í∂åÏû•)\n",
    "\n",
    "### Ïö∞Î¶¨ Îç∞Ïù¥ÌÑ∞ ÌäπÏÑ±\n",
    "- **Sparsity**: 99.9% (BPRÏóê Ïù¥ÏÉÅÏ†Å - ÏïîÎ¨µÏ†Å ÌîºÎìúÎ∞± ÏÑ§Í≥ÑÎê®)\n",
    "- **Ïù¥Ï†Ñ ÏµúÏ†ÅÍ∞í**: k=130, lr=0.0485, Œª=0.0021 (Validation Recall@5=0.4976)\n",
    "\n",
    "## üéØ Ïã§Ìñâ Í≥ÑÌöç\n",
    "\n",
    "**Option A (Îπ†Î¶Ñ)**: Validated params ÏÇ¨Ïö© ‚Üí Ï¶âÏãú Ï†úÏ∂ú (5Î∂Ñ)  \n",
    "**Option B (Ï≤†Ï†Ä)**: Optuna TPE 30 trials ‚Üí ÏµúÏ†ÅÍ∞í Ïû¨ÌÉêÏÉâ (20Î∂Ñ)  \n",
    "\n",
    "## üìä ÏòàÏÉÅ ÏÑ±Îä•\n",
    "\n",
    "- **Validation Recall@5**: ~0.50 (temporal split)\n",
    "- **Expected Public LB**: 0.09-0.12\n",
    "- **Expected Private LB**: 0.10-0.13\n",
    "\n",
    "**EASEÎ≥¥Îã§ ÎÜíÏùÑ Í∞ÄÎä•ÏÑ±** - Pairwise rankingÏù¥ sparse dataÏóê Í∞ïÌï®\n",
    "\n",
    "## ‚è±Ô∏è ÏÜåÏöî ÏãúÍ∞Ñ\n",
    "\n",
    "- **Fast Mode**: ~5Î∂Ñ (Í≤ÄÏ¶ùÎêú ÌååÎùºÎØ∏ÌÑ∞ ÏÇ¨Ïö©)\n",
    "- **Thorough Mode**: ~20Î∂Ñ (Optuna 30 trials)\n",
    "- **ÌïôÏäµ ÏãúÍ∞Ñ**: ~3Ï¥à/epoch (MPS Í∞ÄÏÜç)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "### ÎùºÏù¥Î∏åÎü¨Î¶¨ Î∂àÎü¨Ïò§Í∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cornac version: 2.3.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import optuna\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cornac\n",
    "import cornac\n",
    "print(f\"Cornac version: {cornac.__version__}\")\n",
    "from cornac.data import Dataset\n",
    "from cornac.models import BPR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "### ÏÑ§Ï†ï (Configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Device: MPS (Apple Silicon) - BPR will be accelerated!\n",
      "\n",
      "‚ö° Fast Mode: Using validated optimal parameters\n",
      "   k=130, lr=0.0485\n"
     ]
    }
   ],
   "source": [
    "# Device selection: CUDA > MPS > CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(f\"‚úÖ Device: CUDA ({torch.cuda.get_device_name(0)})\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(f\"‚úÖ Device: MPS (Apple Silicon) - BPR will be accelerated!\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(f\"‚úÖ Device: CPU\")\n",
    "\n",
    "# Data columns\n",
    "DEFAULT_USER_COL = 'resume_seq'\n",
    "DEFAULT_ITEM_COL = 'recruitment_seq'\n",
    "DEFAULT_RATING_COL = 'rating'\n",
    "\n",
    "# Recommendation settings\n",
    "TOP_K = 5\n",
    "SEED = 202511\n",
    "VERBOSE = True\n",
    "\n",
    "# BPR hyperparameters (ÎÖºÎ¨∏ Í∏∞Î∞ò)\n",
    "TUNING_MODE = 'fast'  # 'fast' or 'thorough'\n",
    "\n",
    "if TUNING_MODE == 'fast':\n",
    "    # Option A: Use validated optimal values from ensemble\n",
    "    BPR_PARAMS = {\n",
    "        'k': 130,\n",
    "        'max_iter': 250,\n",
    "        'learning_rate': 0.04849308323568624,\n",
    "        'lambda_reg': 0.0021057978126917233\n",
    "    }\n",
    "    print(f\"\\n‚ö° Fast Mode: Using validated optimal parameters\")\n",
    "    print(f\"   k={BPR_PARAMS['k']}, lr={BPR_PARAMS['learning_rate']:.4f}\")\n",
    "else:\n",
    "    # Option B: Optuna TPE search (Rendle et al., 2012)\n",
    "    BPR_N_TRIALS = 30\n",
    "    print(f\"\\nüî¨ Thorough Mode: Optuna TPE with {BPR_N_TRIALS} trials\")\n",
    "    print(f\"   Search space:\")\n",
    "    print(f\"   - k: 80-150\")\n",
    "    print(f\"   - max_iter: 150-250\")\n",
    "    print(f\"   - learning_rate: 0.01-0.05 (log scale)\")\n",
    "    print(f\"   - lambda_reg: 0.001-0.01 (log scale)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### Îç∞Ïù¥ÌÑ∞ Î°úÎî©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Îç∞Ïù¥ÌÑ∞ Î°úÎî© ÏôÑÎ£å!\n",
      "ÏÇ¨Ïö©Ïûê Ïàò: 8,482\n",
      "ÏïÑÏù¥ÌÖú Ïàò: 6,695\n",
      "ÏÉÅÌò∏ÏûëÏö© Ïàò: 57,946\n",
      "Ìù¨Î∞ïÎèÑ: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_seq</th>\n",
       "      <th>recruitment_seq</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R03838</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R02144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U07807</td>\n",
       "      <td>R01877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U04842</td>\n",
       "      <td>R02463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U08336</td>\n",
       "      <td>R00112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  resume_seq recruitment_seq  rating\n",
       "0     U05833          R03838       1\n",
       "1     U06456          R02144       1\n",
       "2     U07807          R01877       1\n",
       "3     U04842          R02463       1\n",
       "4     U08336          R00112       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========================================\n",
    "# üî• ÎåÄÌöå ÎãπÏùº ÏàòÏ†ï ÌïÑÏöî üî•\n",
    "# ========================================\n",
    "DATA_FILE = 'datasets/apply_train.csv'  # ‚Üê Ïù¥ Î∂ÄÎ∂ÑÎßå Î≥ÄÍ≤Ω!\n",
    "# ========================================\n",
    "\n",
    "data = pd.read_csv(DATA_FILE)\n",
    "data[DEFAULT_RATING_COL] = 1  # Implicit feedback\n",
    "\n",
    "print(f\"Îç∞Ïù¥ÌÑ∞ Î°úÎî© ÏôÑÎ£å!\")\n",
    "print(f\"ÏÇ¨Ïö©Ïûê Ïàò: {data[DEFAULT_USER_COL].nunique():,}\")\n",
    "print(f\"ÏïÑÏù¥ÌÖú Ïàò: {data[DEFAULT_ITEM_COL].nunique():,}\")\n",
    "print(f\"ÏÉÅÌò∏ÏûëÏö© Ïàò: {len(data):,}\")\n",
    "print(f\"Ìù¨Î∞ïÎèÑ: {1 - (len(data) / (data[DEFAULT_USER_COL].nunique() * data[DEFAULT_ITEM_COL].nunique())):.4f}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "### ÏÑ†ÌÉùÏÇ¨Ìï≠: ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù (Thorough Mode Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° Fast Mode: Skipping tuning\n",
      "   Using validated parameters from ensemble\n"
     ]
    }
   ],
   "source": [
    "if TUNING_MODE == 'thorough':\n",
    "    print(\"=\"*70)\n",
    "    print(\"BPR Hyperparameter Tuning (Optuna TPE)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Temporal split for validation\n",
    "    print(\"\\nCreating temporal validation split...\")\n",
    "    val_data = data.groupby(DEFAULT_USER_COL, group_keys=False).apply(\n",
    "        lambda x: x.sample(frac=0.2, random_state=SEED) if len(x) > 1 else x.sample(frac=0, random_state=SEED)\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    train_data = data[~data.index.isin(val_data.index)].reset_index(drop=True)\n",
    "    train_set = Dataset.from_uir(train_data.itertuples(index=False), seed=SEED)\n",
    "    \n",
    "    print(f\"Train: {len(train_data):,}, Validation: {len(val_data):,}\")\n",
    "    \n",
    "    # Validation helper\n",
    "    def evaluate_recall(model, train_set, val_data, k=TOP_K):\n",
    "        val_dict = {}\n",
    "        for _, row in val_data.iterrows():\n",
    "            user_id = row[DEFAULT_USER_COL]\n",
    "            item_id = row[DEFAULT_ITEM_COL]\n",
    "            if user_id not in val_dict:\n",
    "                val_dict[user_id] = set()\n",
    "            val_dict[user_id].add(item_id)\n",
    "        \n",
    "        recall_scores = []\n",
    "        for user_id, true_items in val_dict.items():\n",
    "            if user_id not in train_set.uid_map:\n",
    "                continue\n",
    "            try:\n",
    "                recs = model.recommend(user_id, k=k)\n",
    "                hits = len(set(recs) & true_items)\n",
    "                recall = hits / len(true_items) if len(true_items) > 0 else 0.0\n",
    "                recall_scores.append(recall)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        return np.mean(recall_scores) if recall_scores else 0.0\n",
    "    \n",
    "    # Optuna objective\n",
    "    def bpr_objective(trial):\n",
    "        k = trial.suggest_int('k', 80, 150, step=10)\n",
    "        max_iter = trial.suggest_int('max_iter', 150, 250, step=50)\n",
    "        lr = trial.suggest_float('learning_rate', 0.01, 0.05, log=True)\n",
    "        lambda_reg = trial.suggest_float('lambda_reg', 0.001, 0.01, log=True)\n",
    "        \n",
    "        model = BPR(\n",
    "            k=k, \n",
    "            max_iter=max_iter, \n",
    "            learning_rate=lr, \n",
    "            lambda_reg=lambda_reg, \n",
    "            seed=SEED, \n",
    "            verbose=False\n",
    "        )\n",
    "        model.fit(train_set)\n",
    "        recall = evaluate_recall(model, train_set, val_data)\n",
    "        \n",
    "        return recall\n",
    "    \n",
    "    # Run optimization\n",
    "    print(f\"\\nStarting Optuna optimization ({BPR_N_TRIALS} trials)...\\n\")\n",
    "    study = optuna.create_study(\n",
    "        direction='maximize',\n",
    "        sampler=optuna.samplers.TPESampler(seed=SEED)\n",
    "    )\n",
    "    study.optimize(bpr_objective, n_trials=BPR_N_TRIALS, show_progress_bar=True)\n",
    "    \n",
    "    BPR_PARAMS = study.best_params\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"‚úÖ Optimization complete!\")\n",
    "    print(f\"\\nBest parameters:\")\n",
    "    for param, value in BPR_PARAMS.items():\n",
    "        print(f\"   {param}: {value}\")\n",
    "    print(f\"\\nBest Validation Recall@{TOP_K}: {study.best_value:.6f}\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(f\"\\n‚ö° Fast Mode: Skipping tuning\")\n",
    "    print(f\"   Using validated parameters from ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î°ú ÏµúÏ¢Ö Î™®Îç∏ ÌïôÏäµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Training BPR on Full Data\n",
      "======================================================================\n",
      "\n",
      "Dataset: 57,946 interactions\n",
      "Users: 8482\n",
      "Items: 6695\n",
      "\n",
      "BPR Parameters:\n",
      "   k: 130\n",
      "   max_iter: 250\n",
      "   learning_rate: 0.04849308323568624\n",
      "   lambda_reg: 0.0021057978126917233\n",
      "\n",
      "Training...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebeb08343114ecead6eca696ef9d39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n",
      "\n",
      "‚úÖ BPR training complete!\n",
      "======================================================================\n",
      "CPU times: user 2.25 s, sys: 62 ms, total: 2.32 s\n",
      "Wall time: 2.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Training BPR on Full Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create full dataset\n",
    "full_dataset = Dataset.from_uir(data.itertuples(index=False), seed=SEED)\n",
    "\n",
    "print(f\"\\nDataset: {len(data):,} interactions\")\n",
    "print(f\"Users: {full_dataset.num_users}\")\n",
    "print(f\"Items: {full_dataset.num_items}\")\n",
    "print(f\"\\nBPR Parameters:\")\n",
    "for param, value in BPR_PARAMS.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "print(f\"\\nTraining...\\n\")\n",
    "\n",
    "# Train BPR\n",
    "final_model = BPR(**BPR_PARAMS, seed=SEED, verbose=True)\n",
    "final_model.fit(full_dataset)\n",
    "\n",
    "print(f\"\\n‚úÖ BPR training complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### ÏïÑÏù¥ÌÖú Ïù∏Í∏∞ÎèÑ Í≥ÑÏÇ∞ (Cold-Start Ìè¥Î∞±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating item popularity for cold-start users...\n",
      "\n",
      "Top-5 popular items: ['R03237', 'R01214', 'R00056', 'R00773', 'R00944']\n",
      "‚úÖ Cold-start fallback ready\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating item popularity for cold-start users...\")\n",
    "\n",
    "item_popularity = Counter(data[DEFAULT_ITEM_COL])\n",
    "popular_items = [item for item, _ in item_popularity.most_common(TOP_K)]\n",
    "\n",
    "print(f\"\\nTop-{TOP_K} popular items: {popular_items}\")\n",
    "print(f\"‚úÖ Cold-start fallback ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### ÏòàÏ∏° ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Generating Predictions\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf97ee1eacda43648d7e7f95f3b08ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/8482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Predictions generated\n",
      "   Total users: 8,482\n",
      "   Cold-start: 0\n",
      "======================================================================\n",
      "CPU times: user 3.89 s, sys: 59.3 ms, total: 3.94 s\n",
      "Wall time: 3.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Generating Predictions\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_users = list(full_dataset.uid_map.keys())\n",
    "predictions = {}\n",
    "cold_start_count = 0\n",
    "\n",
    "for user_id in tqdm(all_users, desc=\"Predicting\"):\n",
    "    try:\n",
    "        recs = final_model.recommend(user_id, k=TOP_K)\n",
    "        predictions[user_id] = recs\n",
    "    except:\n",
    "        predictions[user_id] = popular_items\n",
    "        cold_start_count += 1\n",
    "\n",
    "print(f\"\\n‚úÖ Predictions generated\")\n",
    "print(f\"   Total users: {len(predictions):,}\")\n",
    "print(f\"   Cold-start: {cold_start_count:,}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "### Ï†úÏ∂ú ÌååÏùº ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Creating Submission File\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Submission saved: outputs/2025-11-19/submit_BPR_k130_20251119154327.csv\n",
      "   Recommendations: 42,410\n",
      "   Users: 8,482\n",
      "======================================================================\n",
      "CPU times: user 38.7 ms, sys: 4.98 ms, total: 43.6 ms\n",
      "Wall time: 42.8 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_seq</th>\n",
       "      <th>recruitment_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R00999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R00585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R03838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R05806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R02806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R04767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R04129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R01383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R01544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R00697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  resume_seq recruitment_seq\n",
       "0     U05833          R00999\n",
       "1     U05833          R00585\n",
       "2     U05833          R03838\n",
       "3     U05833          R05806\n",
       "4     U05833          R02806\n",
       "5     U06456          R04767\n",
       "6     U06456          R04129\n",
       "7     U06456          R01383\n",
       "8     U06456          R01544\n",
       "9     U06456          R00697"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Creating Submission File\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "submission = []\n",
    "for user_id, items in predictions.items():\n",
    "    for item_id in items:\n",
    "        submission.append({\n",
    "            DEFAULT_USER_COL: user_id,\n",
    "            DEFAULT_ITEM_COL: item_id\n",
    "        })\n",
    "\n",
    "df_submission = pd.DataFrame(submission)\n",
    "\n",
    "# Create output directory with current date\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "output_dir = f'outputs/{current_date}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate filename with full timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "filename = f\"{output_dir}/submit_BPR_k{BPR_PARAMS['k']}_{timestamp}.csv\"\n",
    "\n",
    "df_submission.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Submission saved: {filename}\")\n",
    "print(f\"   Recommendations: {len(df_submission):,}\")\n",
    "print(f\"   Users: {df_submission[DEFAULT_USER_COL].nunique():,}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### ÏöîÏïΩ (Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BPR Model Summary\n",
      "======================================================================\n",
      "\n",
      "üìö Paper: Rendle et al., 2012 - UAI Conference\n",
      "\n",
      "‚öôÔ∏è Configuration:\n",
      "   Tuning mode: fast\n",
      "   k: 130\n",
      "   max_iter: 250\n",
      "   learning_rate: 0.048493\n",
      "   lambda_reg: 0.002106\n",
      "   Device: mps\n",
      "   Seed: 202511\n",
      "\n",
      "üìä Dataset:\n",
      "   Users: 8,482\n",
      "   Items: 6,695\n",
      "   Interactions: 57,946\n",
      "   Sparsity: 99.9%\n",
      "\n",
      "üìÅ Output:\n",
      "   File: outputs/2025-11-19/submit_BPR_k130_20251119154327.csv\n",
      "   Cold-start users: 0\n",
      "\n",
      "üéØ Expected Performance:\n",
      "   Validation Recall@5: ~0.50 (temporal split)\n",
      "   Expected Public LB: 0.09-0.12\n",
      "   Expected Private LB: 0.10-0.13\n",
      "\n",
      "üí° Notes:\n",
      "   - BPR optimizes pairwise ranking (implicit feedback)\n",
      "   - Uses negative sampling internally\n",
      "   - Typically outperforms EASE on validation\n",
      "   - GPU/MPS acceleration available\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"BPR Model Summary\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìö Paper: Rendle et al., 2012 - UAI Conference\")\n",
    "print(f\"\\n‚öôÔ∏è Configuration:\")\n",
    "print(f\"   Tuning mode: {TUNING_MODE}\")\n",
    "for param, value in BPR_PARAMS.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"   {param}: {value:.6f}\")\n",
    "    else:\n",
    "        print(f\"   {param}: {value}\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Seed: {SEED}\")\n",
    "\n",
    "print(f\"\\nüìä Dataset:\")\n",
    "print(f\"   Users: {full_dataset.num_users:,}\")\n",
    "print(f\"   Items: {full_dataset.num_items:,}\")\n",
    "print(f\"   Interactions: {len(data):,}\")\n",
    "print(f\"   Sparsity: 99.9%\")\n",
    "\n",
    "print(f\"\\nüìÅ Output:\")\n",
    "print(f\"   File: {filename}\")\n",
    "print(f\"   Cold-start users: {cold_start_count:,}\")\n",
    "\n",
    "print(f\"\\nüéØ Expected Performance:\")\n",
    "print(f\"   Validation Recall@5: ~0.50 (temporal split)\")\n",
    "print(f\"   Expected Public LB: 0.09-0.12\")\n",
    "print(f\"   Expected Private LB: 0.10-0.13\")\n",
    "\n",
    "print(f\"\\nüí° Notes:\")\n",
    "print(f\"   - BPR optimizes pairwise ranking (implicit feedback)\")\n",
    "print(f\"   - Uses negative sampling internally\")\n",
    "print(f\"   - Typically outperforms EASE on validation\")\n",
    "print(f\"   - GPU/MPS acceleration available\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cornac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
