{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# BPR (Bayesian Personalized Ranking) - ì¶”ì²œ ì‹œìŠ¤í…œ\n",
    "\n",
    "**ë…¼ë¬¸**: Rendle et al., 2012 - \"BPR: Bayesian Personalized Ranking from Implicit Feedback\"  \n",
    "**Conference**: UAI 2012\n",
    "\n",
    "## ğŸ“š ëª¨ë¸ ì„¤ëª…\n",
    "\n",
    "### í•µì‹¬ ì•Œê³ ë¦¬ì¦˜\n",
    "- **Pairwise ranking** ì ‘ê·¼ë²• - ì•„ì´í…œ ê°„ ìƒëŒ€ì  ìˆœìœ„ ìµœì í™”\n",
    "- **ì•”ë¬µì  í”¼ë“œë°±** ì „ìš© - í´ë¦­/êµ¬ë§¤ ì´ë ¥ë§Œìœ¼ë¡œ í•™ìŠµ ê°€ëŠ¥\n",
    "- **ë¶€ì • ìƒ˜í”Œë§** ìë™ ì²˜ë¦¬ - ê¸ì •(ìƒí˜¸ì‘ìš© O)ê³¼ ë¶€ì •(ìƒí˜¸ì‘ìš© X) ìŒ í•™ìŠµ\n",
    "- **Matrix Factorization** ê¸°ë°˜ - ì‚¬ìš©ì/ì•„ì´í…œì„ ì ì¬ ë²¡í„°ë¡œ í‘œí˜„\n",
    "\n",
    "## ğŸ¯ í•µì‹¬ ì „ëµ\n",
    "\n",
    "### íŠœë‹ ì „ëµ (ë…¼ë¬¸ ê¸°ë°˜)\n",
    "1. **Validation**: 80/20 temporal split (ì‹œê°„ ìˆœì„œ ê³ ë ¤)\n",
    "2. **Method**: Optuna TPE (Bayesian optimization)\n",
    "3. **í•µì‹¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°**:\n",
    "   - **k** (latent factors): 80-150 - ì ì¬ ìš”ì¸ ì°¨ì›ìˆ˜\n",
    "   - **learning_rate**: 0.01-0.05 - SGD í•™ìŠµë¥ \n",
    "   - **lambda_reg**: 0.001-0.01 - L2 ì •ê·œí™” ê°•ë„\n",
    "   - **max_iter**: 150-250 - í•™ìŠµ ë°˜ë³µ íšŸìˆ˜\n",
    "4. **Budget**: 20-50 trials (30 trials ê¶Œì¥)\n",
    "\n",
    "### ìš°ë¦¬ ë°ì´í„° íŠ¹ì„±\n",
    "- **Sparsity**: 99.9% (BPRì— ì´ìƒì  - ì•”ë¬µì  í”¼ë“œë°± ì„¤ê³„ë¨)\n",
    "- **ì´ì „ ìµœì ê°’**: k=130, lr=0.0485, Î»=0.0021 (Validation Recall@5=0.4976)\n",
    "\n",
    "## ğŸ¯ ì‹¤í–‰ ê³„íš\n",
    "\n",
    "**Option A (ë¹ ë¦„)**: Validated params ì‚¬ìš© â†’ ì¦‰ì‹œ ì œì¶œ (5ë¶„)  \n",
    "**Option B (ì² ì €)**: Optuna TPE 30 trials â†’ ìµœì ê°’ ì¬íƒìƒ‰ (20ë¶„)  \n",
    "\n",
    "## ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥\n",
    "\n",
    "- **Validation Recall@5**: ~0.50 (temporal split)\n",
    "- **Expected Public LB**: 0.09-0.12\n",
    "- **Expected Private LB**: 0.10-0.13\n",
    "\n",
    "**EASEë³´ë‹¤ ë†’ì„ ê°€ëŠ¥ì„±** - Pairwise rankingì´ sparse dataì— ê°•í•¨\n",
    "\n",
    "## â±ï¸ ì†Œìš” ì‹œê°„\n",
    "\n",
    "- **Fast Mode**: ~5ë¶„ (ê²€ì¦ëœ íŒŒë¼ë¯¸í„° ì‚¬ìš©)\n",
    "- **Thorough Mode**: ~20ë¶„ (Optuna 30 trials)\n",
    "- **í•™ìŠµ ì‹œê°„**: ~3ì´ˆ/epoch (MPS ê°€ì†)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "### ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cornac version: 2.3.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import optuna\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cornac\n",
    "import cornac\n",
    "print(f\"Cornac version: {cornac.__version__}\")\n",
    "from cornac.data import Dataset\n",
    "from cornac.models import BPR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "### ì„¤ì • (Configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ ë° ìµœì í™” ì„¤ì •\n# ============================================================\nprint(\"=\" * 60)\nprint(\"ë””ë°”ì´ìŠ¤ ì„ íƒ ë° ìµœì í™” ì„¤ì •\")\nprint(\"=\" * 60)\n\nif torch.cuda.is_available():\n    device = 'cuda'\n    total_cpus = os.cpu_count() or 4\n    print(f\"ğŸš€ ë””ë°”ì´ìŠ¤: CUDA ({torch.cuda.get_device_name(0)})\")\n    print(f\"   ì‚¬ìš© ê°€ëŠ¥ CPU: {total_cpus}ì½”ì–´\")\n    print(f\"   GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\nelif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n    device = 'mps'\n    total_cpus = os.cpu_count() or 4\n    print(f\"ğŸ ë””ë°”ì´ìŠ¤: MPS (Apple Silicon)\")\n    print(f\"   ì‚¬ìš© ê°€ëŠ¥ CPU: {total_cpus}ì½”ì–´\")\nelse:\n    device = 'cpu'\n    total_cpus = os.cpu_count() or 4\n    print(f\"ğŸ’» ë””ë°”ì´ìŠ¤: CPU\")\n    print(f\"   ì‚¬ìš© ê°€ëŠ¥ CPU: {total_cpus}ì½”ì–´\")\n\nprint(f\"PyTorch version: {torch.__version__}\\n\")\n\n# Data columns\nDEFAULT_USER_COL = 'user_id'\nDEFAULT_ITEM_COL = 'item_id'\nDEFAULT_RATING_COL = 'rating'\n\n# Recommendation settings\nTOP_K = 5\nSEED = 202511\nVERBOSE = True\n\n# BPR hyperparameters (ë…¼ë¬¸ ê¸°ë°˜)\nTUNING_MODE = 'fast'  # 'fast' or 'thorough'\n\nif TUNING_MODE == 'fast':\n    # Option A: Use validated optimal values from ensemble\n    BPR_PARAMS = {\n        'k': 130,\n        'max_iter': 250,\n        'learning_rate': 0.04849308323568624,\n        'lambda_reg': 0.0021057978126917233\n    }\n    print(f\"âš¡ Fast Mode: Using validated optimal parameters\")\n    print(f\"   k={BPR_PARAMS['k']}, lr={BPR_PARAMS['learning_rate']:.4f}\")\nelse:\n    # Option B: Optuna TPE search (Rendle et al., 2012)\n    BPR_N_TRIALS = 30\n    print(f\"ğŸ”¬ Thorough Mode: Optuna TPE with {BPR_N_TRIALS} trials\")\n    print(f\"   Search space:\")\n    print(f\"   - k: 80-150\")\n    print(f\"   - max_iter: 150-250\")\n    print(f\"   - learning_rate: 0.01-0.05 (log scale)\")\n    print(f\"   - lambda_reg: 0.001-0.01 (log scale)\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ë¡œë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "# ========================================\n# ğŸ”¥ ëŒ€íšŒ ë‹¹ì¼ ìˆ˜ì • í•„ìš” ğŸ”¥\n# ========================================\nDATA_FILE = 'datasets/comp_train.csv'  # â† ì´ ë¶€ë¶„ë§Œ ë³€ê²½!\n# ========================================\n\ndata = pd.read_csv(DATA_FILE)\ndata[DEFAULT_RATING_COL] = 1  # Implicit feedback\n\nprint(f\"ë°ì´í„° ë¡œë”© ì™„ë£Œ!\")\nprint(f\"ì‚¬ìš©ì ìˆ˜: {data[DEFAULT_USER_COL].nunique():,}\")\nprint(f\"ì•„ì´í…œ ìˆ˜: {data[DEFAULT_ITEM_COL].nunique():,}\")\nprint(f\"ìƒí˜¸ì‘ìš© ìˆ˜: {len(data):,}\")\nprint(f\"í¬ë°•ë„: {1 - (len(data) / (data[DEFAULT_USER_COL].nunique() * data[DEFAULT_ITEM_COL].nunique())):.4f}\")\ndata.head()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "### ì„ íƒì‚¬í•­: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Thorough Mode Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BPR Hyperparameter Tuning (Optuna TPE)\n",
      "======================================================================\n",
      "\n",
      "Creating temporal validation split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_279502/742272474.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_data = data.groupby(DEFAULT_USER_COL, group_keys=False).apply(\n",
      "[I 2025-11-21 12:59:30,309] A new study created in memory with name: no-name-5fdc8c3f-4ad4-4c3e-b771-fd1930a9f3ae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 46,190, Validation: 11,756\n",
      "\n",
      "Starting Optuna optimization (30 trials)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f160415a13949b99d2eafd741e3ccf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-21 12:59:31,835] Trial 0 finished with value: 0.0342554445951347 and parameters: {'k': 80, 'max_iter': 200, 'learning_rate': 0.010409078594736706, 'lambda_reg': 0.007271923520597102}. Best is trial 0 with value: 0.0342554445951347.\n",
      "[I 2025-11-21 12:59:33,338] Trial 1 finished with value: 0.21766283932925767 and parameters: {'k': 130, 'max_iter': 150, 'learning_rate': 0.022875628022894296, 'lambda_reg': 0.008958538988734898}. Best is trial 1 with value: 0.21766283932925767.\n",
      "[I 2025-11-21 12:59:35,287] Trial 2 finished with value: 0.406237211090459 and parameters: {'k': 120, 'max_iter': 200, 'learning_rate': 0.033437520031340456, 'lambda_reg': 0.0011003013691562446}. Best is trial 2 with value: 0.406237211090459.\n",
      "[I 2025-11-21 12:59:37,259] Trial 3 finished with value: 0.4418126073370412 and parameters: {'k': 110, 'max_iter': 250, 'learning_rate': 0.03188216931403481, 'lambda_reg': 0.0015616170687685806}. Best is trial 3 with value: 0.4418126073370412.\n",
      "[I 2025-11-21 12:59:39,106] Trial 4 finished with value: 0.2612421336609358 and parameters: {'k': 100, 'max_iter': 250, 'learning_rate': 0.014924391231749596, 'lambda_reg': 0.0011569619736783935}. Best is trial 3 with value: 0.4418126073370412.\n",
      "[I 2025-11-21 12:59:40,928] Trial 5 finished with value: 0.40312475400377656 and parameters: {'k': 90, 'max_iter': 250, 'learning_rate': 0.024896062922412154, 'lambda_reg': 0.00475487049729365}. Best is trial 3 with value: 0.4418126073370412.\n",
      "[I 2025-11-21 12:59:42,641] Trial 6 finished with value: 0.41241013117130515 and parameters: {'k': 80, 'max_iter': 250, 'learning_rate': 0.02548860020122964, 'lambda_reg': 0.004749508760656832}. Best is trial 3 with value: 0.4418126073370412.\n",
      "[I 2025-11-21 12:59:44,553] Trial 7 finished with value: 0.06547015054538892 and parameters: {'k': 150, 'max_iter': 200, 'learning_rate': 0.012243340862760617, 'lambda_reg': 0.0010552227443656693}. Best is trial 3 with value: 0.4418126073370412.\n",
      "[I 2025-11-21 12:59:46,336] Trial 8 finished with value: 0.3963226586848458 and parameters: {'k': 150, 'max_iter': 150, 'learning_rate': 0.041356793141182346, 'lambda_reg': 0.003415261331429121}. Best is trial 3 with value: 0.4418126073370412.\n",
      "[I 2025-11-21 12:59:48,295] Trial 9 finished with value: 0.21695333164716357 and parameters: {'k': 110, 'max_iter': 250, 'learning_rate': 0.013743814142378307, 'lambda_reg': 0.00806631758358884}. Best is trial 3 with value: 0.4418126073370412.\n",
      "[I 2025-11-21 12:59:50,345] Trial 10 finished with value: 0.4952218293063049 and parameters: {'k': 130, 'max_iter': 250, 'learning_rate': 0.04709165549519499, 'lambda_reg': 0.0020937865578456367}. Best is trial 10 with value: 0.4952218293063049.\n",
      "[I 2025-11-21 12:59:52,522] Trial 11 finished with value: 0.49755624747057997 and parameters: {'k': 130, 'max_iter': 250, 'learning_rate': 0.04849308323568622, 'lambda_reg': 0.0021057978126917233}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 12:59:54,224] Trial 12 finished with value: 0.46692093993941436 and parameters: {'k': 130, 'max_iter': 200, 'learning_rate': 0.0473235789956772, 'lambda_reg': 0.0020306651343047935}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 12:59:56,373] Trial 13 finished with value: 0.4676645075557472 and parameters: {'k': 130, 'max_iter': 250, 'learning_rate': 0.038033991805235236, 'lambda_reg': 0.00224830311303578}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 12:59:58,294] Trial 14 finished with value: 0.4632841048998677 and parameters: {'k': 140, 'max_iter': 200, 'learning_rate': 0.04828458805177737, 'lambda_reg': 0.0025926028179778424}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 13:00:00,234] Trial 15 finished with value: 0.29823488448711927 and parameters: {'k': 120, 'max_iter': 250, 'learning_rate': 0.01704759199607777, 'lambda_reg': 0.0016223279911846422}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 13:00:02,369] Trial 16 finished with value: 0.42942949812735276 and parameters: {'k': 140, 'max_iter': 250, 'learning_rate': 0.029976316457945684, 'lambda_reg': 0.003337488601554813}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 13:00:04,183] Trial 17 finished with value: 0.2511551995051697 and parameters: {'k': 140, 'max_iter': 200, 'learning_rate': 0.018724356423874048, 'lambda_reg': 0.001587385828429412}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 13:00:05,831] Trial 18 finished with value: 0.3924426197891633 and parameters: {'k': 120, 'max_iter': 150, 'learning_rate': 0.04046807863175717, 'lambda_reg': 0.0027170925050447174}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 13:00:07,674] Trial 19 finished with value: 0.4874192553572768 and parameters: {'k': 100, 'max_iter': 250, 'learning_rate': 0.04961346363254397, 'lambda_reg': 0.0038935124292115712}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 13:00:09,579] Trial 20 finished with value: 0.43259647831310527 and parameters: {'k': 130, 'max_iter': 200, 'learning_rate': 0.03631235761629943, 'lambda_reg': 0.0020158617521044515}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 13:00:11,623] Trial 21 finished with value: 0.4765845815719177 and parameters: {'k': 100, 'max_iter': 250, 'learning_rate': 0.04583265656932143, 'lambda_reg': 0.004894941646600756}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 13:00:13,461] Trial 22 finished with value: 0.4874556743746255 and parameters: {'k': 100, 'max_iter': 250, 'learning_rate': 0.0493506388783385, 'lambda_reg': 0.003786527439401064}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 13:00:15,405] Trial 23 finished with value: 0.4604099354658055 and parameters: {'k': 110, 'max_iter': 250, 'learning_rate': 0.04222685169263664, 'lambda_reg': 0.00619587398281519}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 13:00:17,240] Trial 24 finished with value: 0.42275846546183254 and parameters: {'k': 90, 'max_iter': 250, 'learning_rate': 0.0281866226576311, 'lambda_reg': 0.002534628499963016}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 13:00:19,273] Trial 25 finished with value: 0.4504368950808164 and parameters: {'k': 120, 'max_iter': 250, 'learning_rate': 0.03641781049106736, 'lambda_reg': 0.0013815146773102284}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 13:00:21,385] Trial 26 finished with value: 0.4809693232704258 and parameters: {'k': 140, 'max_iter': 250, 'learning_rate': 0.0435560929954178, 'lambda_reg': 0.0018466583976914745}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 13:00:22,982] Trial 27 finished with value: 0.4194227963633506 and parameters: {'k': 90, 'max_iter': 200, 'learning_rate': 0.03374466412274566, 'lambda_reg': 0.004007562703513241}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 13:00:24,961] Trial 28 finished with value: 0.4719660901275919 and parameters: {'k': 130, 'max_iter': 250, 'learning_rate': 0.03937360550474996, 'lambda_reg': 0.0028965837606527416}. Best is trial 11 with value: 0.49755624747057997.\n",
      "[I 2025-11-21 13:00:26,454] Trial 29 finished with value: 0.47146796431286897 and parameters: {'k': 80, 'max_iter': 200, 'learning_rate': 0.048745127812770586, 'lambda_reg': 0.002312638515595999}. Best is trial 11 with value: 0.49755624747057997.\n",
      "\n",
      "======================================================================\n",
      "âœ… Optimization complete!\n",
      "\n",
      "Best parameters:\n",
      "   k: 130\n",
      "   max_iter: 250\n",
      "   learning_rate: 0.04849308323568622\n",
      "   lambda_reg: 0.0021057978126917233\n",
      "\n",
      "Best Validation Recall@5: 0.497556\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "if TUNING_MODE == 'thorough':\n",
    "    print(\"=\"*70)\n",
    "    print(\"BPR Hyperparameter Tuning (Optuna TPE)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Temporal split for validation\n",
    "    print(\"\\nCreating temporal validation split...\")\n",
    "    val_data = data.groupby(DEFAULT_USER_COL, group_keys=False).apply(\n",
    "        lambda x: x.sample(frac=0.2, random_state=SEED) if len(x) > 1 else x.sample(frac=0, random_state=SEED)\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    train_data = data[~data.index.isin(val_data.index)].reset_index(drop=True)\n",
    "    train_set = Dataset.from_uir(train_data.itertuples(index=False), seed=SEED)\n",
    "    \n",
    "    print(f\"Train: {len(train_data):,}, Validation: {len(val_data):,}\")\n",
    "    \n",
    "    # Validation helper\n",
    "    def evaluate_recall(model, train_set, val_data, k=TOP_K):\n",
    "        val_dict = {}\n",
    "        for _, row in val_data.iterrows():\n",
    "            user_id = row[DEFAULT_USER_COL]\n",
    "            item_id = row[DEFAULT_ITEM_COL]\n",
    "            if user_id not in val_dict:\n",
    "                val_dict[user_id] = set()\n",
    "            val_dict[user_id].add(item_id)\n",
    "        \n",
    "        recall_scores = []\n",
    "        for user_id, true_items in val_dict.items():\n",
    "            if user_id not in train_set.uid_map:\n",
    "                continue\n",
    "            try:\n",
    "                recs = model.recommend(user_id, k=k)\n",
    "                hits = len(set(recs) & true_items)\n",
    "                recall = hits / len(true_items) if len(true_items) > 0 else 0.0\n",
    "                recall_scores.append(recall)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        return np.mean(recall_scores) if recall_scores else 0.0\n",
    "    \n",
    "    # Optuna objective\n",
    "    def bpr_objective(trial):\n",
    "        k = trial.suggest_int('k', 80, 150, step=10)\n",
    "        max_iter = trial.suggest_int('max_iter', 150, 250, step=50)\n",
    "        lr = trial.suggest_float('learning_rate', 0.01, 0.05, log=True)\n",
    "        lambda_reg = trial.suggest_float('lambda_reg', 0.001, 0.01, log=True)\n",
    "        \n",
    "        model = BPR(\n",
    "            k=k, \n",
    "            max_iter=max_iter, \n",
    "            learning_rate=lr, \n",
    "            lambda_reg=lambda_reg, \n",
    "            seed=SEED, \n",
    "            verbose=False\n",
    "        )\n",
    "        model.fit(train_set)\n",
    "        recall = evaluate_recall(model, train_set, val_data)\n",
    "        \n",
    "        return recall\n",
    "    \n",
    "    # Run optimization\n",
    "    print(f\"\\nStarting Optuna optimization ({BPR_N_TRIALS} trials)...\\n\")\n",
    "    study = optuna.create_study(\n",
    "        direction='maximize',\n",
    "        sampler=optuna.samplers.TPESampler(seed=SEED)\n",
    "    )\n",
    "    study.optimize(bpr_objective, n_trials=BPR_N_TRIALS, show_progress_bar=True)\n",
    "    \n",
    "    BPR_PARAMS = study.best_params\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"âœ… Optimization complete!\")\n",
    "    print(f\"\\nBest parameters:\")\n",
    "    for param, value in BPR_PARAMS.items():\n",
    "        print(f\"   {param}: {value}\")\n",
    "    print(f\"\\nBest Validation Recall@{TOP_K}: {study.best_value:.6f}\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(f\"\\nâš¡ Fast Mode: Skipping tuning\")\n",
    "    print(f\"   Using validated parameters from ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Training BPR on Full Data\n",
      "======================================================================\n",
      "\n",
      "Dataset: 57,946 interactions\n",
      "Users: 8482\n",
      "Items: 6695\n",
      "\n",
      "BPR Parameters:\n",
      "   k: 130\n",
      "   max_iter: 250\n",
      "   learning_rate: 0.04849308323568622\n",
      "   lambda_reg: 0.0021057978126917233\n",
      "\n",
      "Training...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc5dfc32a7e470480576b2d259bb570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n",
      "\n",
      "âœ… BPR training complete!\n",
      "======================================================================\n",
      "CPU times: user 2.2 s, sys: 11 ms, total: 2.21 s\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Training BPR on Full Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create full dataset\n",
    "full_dataset = Dataset.from_uir(data.itertuples(index=False), seed=SEED)\n",
    "\n",
    "print(f\"\\nDataset: {len(data):,} interactions\")\n",
    "print(f\"Users: {full_dataset.num_users}\")\n",
    "print(f\"Items: {full_dataset.num_items}\")\n",
    "print(f\"\\nBPR Parameters:\")\n",
    "for param, value in BPR_PARAMS.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "print(f\"\\nTraining...\\n\")\n",
    "\n",
    "# Train BPR\n",
    "final_model = BPR(**BPR_PARAMS, seed=SEED, verbose=True)\n",
    "final_model.fit(full_dataset)\n",
    "\n",
    "print(f\"\\nâœ… BPR training complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### ì•„ì´í…œ ì¸ê¸°ë„ ê³„ì‚° (Cold-Start í´ë°±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating item popularity for cold-start users...\n",
      "\n",
      "Top-5 popular items: ['R03237', 'R01214', 'R00056', 'R00773', 'R00944']\n",
      "âœ… Cold-start fallback ready\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating item popularity for cold-start users...\")\n",
    "\n",
    "item_popularity = Counter(data[DEFAULT_ITEM_COL])\n",
    "popular_items = [item for item, _ in item_popularity.most_common(TOP_K)]\n",
    "\n",
    "print(f\"\\nTop-{TOP_K} popular items: {popular_items}\")\n",
    "print(f\"âœ… Cold-start fallback ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### ì˜ˆì¸¡ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Generating Predictions\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8c171188504cdb9991cb5ec29007d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/8482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Predictions generated\n",
      "   Total users: 8,482\n",
      "   Cold-start: 0\n",
      "======================================================================\n",
      "CPU times: user 6.1 s, sys: 6.85 ms, total: 6.1 s\n",
      "Wall time: 859 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Generating Predictions\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_users = list(full_dataset.uid_map.keys())\n",
    "predictions = {}\n",
    "cold_start_count = 0\n",
    "\n",
    "for user_id in tqdm(all_users, desc=\"Predicting\"):\n",
    "    try:\n",
    "        recs = final_model.recommend(user_id, k=TOP_K)\n",
    "        predictions[user_id] = recs\n",
    "    except:\n",
    "        predictions[user_id] = popular_items\n",
    "        cold_start_count += 1\n",
    "\n",
    "print(f\"\\nâœ… Predictions generated\")\n",
    "print(f\"   Total users: {len(predictions):,}\")\n",
    "print(f\"   Cold-start: {cold_start_count:,}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "### ì œì¶œ íŒŒì¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "%%time\n\nprint(\"=\"*70)\nprint(\"Creating Submission File\")\nprint(\"=\"*70)\n\nsubmission = []\nfor user_id, items in predictions.items():\n    for item_id in items:\n        submission.append({\n            DEFAULT_USER_COL: user_id,\n            DEFAULT_ITEM_COL: item_id\n        })\n\ndf_submission = pd.DataFrame(submission)\n\n# user_idë³„ë¡œ item_idë¥¼ ê³µë°±ìœ¼ë¡œ ì—°ê²° (ì œì¶œ í˜•ì‹)\nsubmit = df_submission.groupby(DEFAULT_USER_COL)[DEFAULT_ITEM_COL].apply(lambda x: ' '.join(x)).reset_index()\nsubmit.columns = [DEFAULT_USER_COL, 'item_ids']\n\n# Create output directory with current date\ncurrent_date = datetime.now().strftime('%Y-%m-%d')\noutput_dir = f'outputs/{current_date}'\nos.makedirs(output_dir, exist_ok=True)\n\n# Generate filename with full timestamp\ntimestamp = datetime.now().strftime('%Y%m%d%H%M%S')\nfilename = f\"{output_dir}/submit_BPR_k{BPR_PARAMS['k']}_{timestamp}.csv\"\n\nsubmit.to_csv(filename, index=False)\n\nprint(f\"\\nâœ… Submission saved: {filename}\")\nprint(f\"   Format: user_id | item_ids (space-separated)\")\nprint(f\"   Total users: {len(submit):,}\")\nprint(\"=\"*70)\n\nsubmit.head(10)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### ìš”ì•½ (Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BPR Model Summary\n",
      "======================================================================\n",
      "\n",
      "ğŸ“š Paper: Rendle et al., 2012 - UAI Conference\n",
      "\n",
      "âš™ï¸ Configuration:\n",
      "   Tuning mode: thorough\n",
      "   k: 130\n",
      "   max_iter: 250\n",
      "   learning_rate: 0.048493\n",
      "   lambda_reg: 0.002106\n",
      "   Device: cuda\n",
      "   Seed: 202511\n",
      "\n",
      "ğŸ“Š Dataset:\n",
      "   Users: 8,482\n",
      "   Items: 6,695\n",
      "   Interactions: 57,946\n",
      "   Sparsity: 99.9%\n",
      "\n",
      "ğŸ“ Output:\n",
      "   File: outputs/2025-11-21/submit_BPR_k130_20251121130049.csv\n",
      "   Cold-start users: 0\n",
      "\n",
      "ğŸ¯ Expected Performance:\n",
      "   Validation Recall@5: ~0.50 (temporal split)\n",
      "   Expected Public LB: 0.09-0.12\n",
      "   Expected Private LB: 0.10-0.13\n",
      "\n",
      "ğŸ’¡ Notes:\n",
      "   - BPR optimizes pairwise ranking (implicit feedback)\n",
      "   - Uses negative sampling internally\n",
      "   - Typically outperforms EASE on validation\n",
      "   - GPU/MPS acceleration available\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"BPR Model Summary\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nğŸ“š Paper: Rendle et al., 2012 - UAI Conference\")\n",
    "print(f\"\\nâš™ï¸ Configuration:\")\n",
    "print(f\"   Tuning mode: {TUNING_MODE}\")\n",
    "for param, value in BPR_PARAMS.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"   {param}: {value:.6f}\")\n",
    "    else:\n",
    "        print(f\"   {param}: {value}\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Seed: {SEED}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset:\")\n",
    "print(f\"   Users: {full_dataset.num_users:,}\")\n",
    "print(f\"   Items: {full_dataset.num_items:,}\")\n",
    "print(f\"   Interactions: {len(data):,}\")\n",
    "print(f\"   Sparsity: 99.9%\")\n",
    "\n",
    "print(f\"\\nğŸ“ Output:\")\n",
    "print(f\"   File: {filename}\")\n",
    "print(f\"   Cold-start users: {cold_start_count:,}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Expected Performance:\")\n",
    "print(f\"   Validation Recall@5: ~0.50 (temporal split)\")\n",
    "print(f\"   Expected Public LB: 0.09-0.12\")\n",
    "print(f\"   Expected Private LB: 0.10-0.13\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Notes:\")\n",
    "print(f\"   - BPR optimizes pairwise ranking (implicit feedback)\")\n",
    "print(f\"   - Uses negative sampling internally\")\n",
    "print(f\"   - Typically outperforms EASE on validation\")\n",
    "print(f\"   - GPU/MPS acceleration available\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62498fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cornac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}