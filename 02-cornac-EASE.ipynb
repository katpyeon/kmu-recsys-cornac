{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# EASE (Embarrassingly Shallow Autoencoders) - ÎÖºÎ¨∏ Í∏∞Î∞ò\n",
    "\n",
    "## ÌïµÏã¨ Ï†ÑÎûµ ÏöîÏïΩ\n",
    "\n",
    "**Î™®Îç∏**: EASE (Steck, 2019, WWW)  \n",
    "**ÌïµÏã¨ ÏõêÎ¶¨**: ÏÑ†Ìòï Ïò§ÌÜ†Ïù∏ÏΩîÎçî + L2 Ï†ïÍ∑úÌôî\n",
    "\n",
    "**ÏµúÏ†ÅÌôî Ï†ÑÎûµ:**\n",
    "- ‚úÖ Œª=100 (Validation Recall@5: 0.4058ÏóêÏÑú Í≤ÄÏ¶ùÎê®)\n",
    "- ‚úÖ Closed-form Ìï¥Í≤∞ (Îπ†Î•∏ ÌïôÏäµ, ~5Î∂Ñ)\n",
    "- ‚úÖ 99.9% Ìù¨ÏÜå Îç∞Ïù¥ÌÑ∞Ïóê ÏµúÏ†ÅÌôî\n",
    "- ‚úÖ Cold-start Ïù∏Í∏∞ÎèÑ Ìè¥Î∞±\n",
    "\n",
    "**ÎÖºÎ¨∏ Í∂åÏû• ÏÇ¨Ìï≠:**\n",
    "1. **Í≤ÄÏ¶ù**: Îã®Ïùº 80/20 split (ÍµêÏ∞® Í≤ÄÏ¶ù ÏóÜÏùå)\n",
    "2. **Œª ÌÉêÏÉâ**: 7-10Í∞ú Í∞íÏóê ÎåÄÌïú Í∑∏Î¶¨Îìú ÏÑúÏπò\n",
    "3. **Ìù¨ÏÜå Îç∞Ïù¥ÌÑ∞ ÏµúÏ†Å Œª (99%+)**: 500-1000\n",
    "4. **ÌÉêÏÉâ Í≥µÍ∞Ñ**: [100, 250, 500, 750, 1000, 1500, 2000]\n",
    "\n",
    "**Ïã§Ìñâ ÏòµÏÖò:**\n",
    "- **Îπ†Î•∏ Î™®Îìú (Í∏∞Î≥∏)**: Œª=100 Í≥†Ï†ï ‚Üí Ï¶âÏãú Ï†úÏ∂ú (5Î∂Ñ)  \n",
    "- **Ï≤†Ï†Ä Î™®Îìú**: Í∑∏Î¶¨Îìú ÏÑúÏπò 7Í∞ú Œª ‚Üí ÏµúÏ†ÅÍ∞í ÏÑ†ÌÉù (7Î∂Ñ)\n",
    "\n",
    "**ÏòàÏÉÅ ÏÑ±Îä•:**\n",
    "- Validation Recall@5: ~0.40\n",
    "- Expected Public LB: 0.08-0.10\n",
    "- Expected Private LB: 0.09-0.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "### ÎùºÏù¥Î∏åÎü¨Î¶¨ Î∂àÎü¨Ïò§Í∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cornac version: 2.3.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Cornac\n",
    "import cornac\n",
    "print(f\"Cornac version: {cornac.__version__}\")\n",
    "from cornac.data import Dataset\n",
    "from cornac.models import EASE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "### ÏÑ§Ï†ï (Configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Device: MPS (Apple Silicon)\n",
      "\n",
      "‚ö° Fast Mode: Using Œª=100 (validated optimal)\n"
     ]
    }
   ],
   "source": [
    "# Device selection: CUDA > MPS > CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(f\"‚úÖ Device: CUDA ({torch.cuda.get_device_name(0)})\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(f\"‚úÖ Device: MPS (Apple Silicon)\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(f\"‚úÖ Device: CPU\")\n",
    "\n",
    "# Data columns\n",
    "DEFAULT_USER_COL = 'resume_seq'\n",
    "DEFAULT_ITEM_COL = 'recruitment_seq'\n",
    "DEFAULT_RATING_COL = 'rating'\n",
    "\n",
    "# Recommendation settings\n",
    "TOP_K = 5\n",
    "SEED = 202511\n",
    "VERBOSE = True\n",
    "\n",
    "# EASE hyperparameters (ÎÖºÎ¨∏ Í∏∞Î∞ò)\n",
    "TUNING_MODE = 'fast'  # 'fast' or 'thorough'\n",
    "\n",
    "if TUNING_MODE == 'fast':\n",
    "    # Option A: Use validated optimal value\n",
    "    EASE_LAMBDA = 100  # From ensemble validation\n",
    "    print(f\"\\n‚ö° Fast Mode: Using Œª={EASE_LAMBDA} (validated optimal)\")\n",
    "else:\n",
    "    # Option B: Grid search (Steck, 2019)\n",
    "    EASE_LAMBDAS = [100, 250, 500, 750, 1000, 1500, 2000]\n",
    "    print(f\"\\nüî¨ Thorough Mode: Grid search on {len(EASE_LAMBDAS)} lambda values\")\n",
    "    print(f\"   Search space: {EASE_LAMBDAS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### Îç∞Ïù¥ÌÑ∞ Î°úÎî©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Îç∞Ïù¥ÌÑ∞ Î°úÎî© ÏôÑÎ£å!\n",
      "ÏÇ¨Ïö©Ïûê Ïàò: 8,482\n",
      "ÏïÑÏù¥ÌÖú Ïàò: 6,695\n",
      "ÏÉÅÌò∏ÏûëÏö© Ïàò: 57,946\n",
      "Ìù¨Î∞ïÎèÑ: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_seq</th>\n",
       "      <th>recruitment_seq</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R03838</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R02144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U07807</td>\n",
       "      <td>R01877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U04842</td>\n",
       "      <td>R02463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U08336</td>\n",
       "      <td>R00112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  resume_seq recruitment_seq  rating\n",
       "0     U05833          R03838       1\n",
       "1     U06456          R02144       1\n",
       "2     U07807          R01877       1\n",
       "3     U04842          R02463       1\n",
       "4     U08336          R00112       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========================================\n",
    "# üî• Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú ÏÑ§Ï†ï üî•\n",
    "# ========================================\n",
    "DATA_FILE = 'datasets/apply_train.csv'\n",
    "# ========================================\n",
    "\n",
    "data = pd.read_csv(DATA_FILE)\n",
    "data[DEFAULT_RATING_COL] = 1  # Implicit feedback\n",
    "\n",
    "print(f\"Îç∞Ïù¥ÌÑ∞ Î°úÎî© ÏôÑÎ£å!\")\n",
    "print(f\"ÏÇ¨Ïö©Ïûê Ïàò: {data[DEFAULT_USER_COL].nunique():,}\")\n",
    "print(f\"ÏïÑÏù¥ÌÖú Ïàò: {data[DEFAULT_ITEM_COL].nunique():,}\")\n",
    "print(f\"ÏÉÅÌò∏ÏûëÏö© Ïàò: {len(data):,}\")\n",
    "print(f\"Ìù¨Î∞ïÎèÑ: {1 - (len(data) / (data[DEFAULT_USER_COL].nunique() * data[DEFAULT_ITEM_COL].nunique())):.4f}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "### ÏÑ†ÌÉùÏÇ¨Ìï≠: Í≤ÄÏ¶ù (Ï≤†Ï†Ä Î™®ÎìúÎßå Ìï¥Îãπ)\n",
    "**Îπ†Î•∏ Î™®ÎìúÏóêÏÑúÎäî Í±¥ÎÑàÎúÄ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Fast Mode: Skipping validation, using Œª=100\n"
     ]
    }
   ],
   "source": [
    "if TUNING_MODE == 'thorough':\n",
    "    print(\"Creating validation split for lambda search...\")\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Temporal split (ÎÖºÎ¨∏ Í∂åÏû•)\n",
    "    val_data = data.groupby(DEFAULT_USER_COL, group_keys=False).apply(\n",
    "        lambda x: x.sample(frac=0.2, random_state=SEED) if len(x) > 1 else x.sample(frac=0, random_state=SEED)\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    train_data = data[~data.index.isin(val_data.index)].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Train: {len(train_data):,}, Validation: {len(val_data):,}\")\n",
    "    \n",
    "    train_set = Dataset.from_uir(train_data.itertuples(index=False), seed=SEED)\n",
    "    \n",
    "    # Validation helper\n",
    "    def evaluate_recall(model, train_set, val_data, k=TOP_K):\n",
    "        val_dict = {}\n",
    "        for _, row in val_data.iterrows():\n",
    "            user_id = row[DEFAULT_USER_COL]\n",
    "            item_id = row[DEFAULT_ITEM_COL]\n",
    "            if user_id not in val_dict:\n",
    "                val_dict[user_id] = set()\n",
    "            val_dict[user_id].add(item_id)\n",
    "        \n",
    "        recall_scores = []\n",
    "        for user_id, true_items in val_dict.items():\n",
    "            if user_id not in train_set.uid_map:\n",
    "                continue\n",
    "            try:\n",
    "                recs = model.recommend(user_id, k=k)\n",
    "                hits = len(set(recs) & true_items)\n",
    "                recall = hits / len(true_items) if len(true_items) > 0 else 0.0\n",
    "                recall_scores.append(recall)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        return np.mean(recall_scores) if recall_scores else 0.0\n",
    "    \n",
    "    # Grid search\n",
    "    print(f\"\\nGrid search on {len(EASE_LAMBDAS)} lambda values...\")\n",
    "    results = {}\n",
    "    \n",
    "    for lamb in tqdm(EASE_LAMBDAS, desc=\"EASE Grid Search\"):\n",
    "        model = EASE(lamb=lamb, verbose=False, seed=SEED)\n",
    "        model.fit(train_set)\n",
    "        recall = evaluate_recall(model, train_set, val_data)\n",
    "        results[lamb] = recall\n",
    "        print(f\"  Œª={lamb:>4}: Recall@{TOP_K}={recall:.6f}\")\n",
    "    \n",
    "    EASE_LAMBDA = max(results, key=results.get)\n",
    "    print(f\"\\n‚úÖ Best Œª: {EASE_LAMBDA} (Recall@{TOP_K}={results[EASE_LAMBDA]:.6f})\")\n",
    "else:\n",
    "    print(f\"‚ö° Fast Mode: Skipping validation, using Œª={EASE_LAMBDA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î°ú ÏµúÏ¢Ö Î™®Îç∏ ÌïôÏäµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Training EASE on Full Data\n",
      "======================================================================\n",
      "\n",
      "Dataset: 57,946 interactions\n",
      "Users: 8482\n",
      "Items: 6695\n",
      "\n",
      "Training EASE with Œª=100...\n",
      "\n",
      "\n",
      "‚úÖ EASE training complete!\n",
      "======================================================================\n",
      "CPU times: user 9.7 s, sys: 318 ms, total: 10 s\n",
      "Wall time: 5.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Training EASE on Full Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create full dataset\n",
    "full_dataset = Dataset.from_uir(data.itertuples(index=False), seed=SEED)\n",
    "\n",
    "print(f\"\\nDataset: {len(data):,} interactions\")\n",
    "print(f\"Users: {full_dataset.num_users}\")\n",
    "print(f\"Items: {full_dataset.num_items}\")\n",
    "print(f\"\\nTraining EASE with Œª={EASE_LAMBDA}...\\n\")\n",
    "\n",
    "# Train EASE\n",
    "final_model = EASE(lamb=EASE_LAMBDA, verbose=True, seed=SEED)\n",
    "final_model.fit(full_dataset)\n",
    "\n",
    "print(f\"\\n‚úÖ EASE training complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### ÏïÑÏù¥ÌÖú Ïù∏Í∏∞ÎèÑ Í≥ÑÏÇ∞ (Cold-Start Ìè¥Î∞±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating item popularity for cold-start users...\n",
      "\n",
      "Top-5 popular items: ['R03237', 'R01214', 'R00056', 'R00773', 'R00944']\n",
      "‚úÖ Cold-start fallback ready\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating item popularity for cold-start users...\")\n",
    "\n",
    "item_popularity = Counter(data[DEFAULT_ITEM_COL])\n",
    "popular_items = [item for item, _ in item_popularity.most_common(TOP_K)]\n",
    "\n",
    "print(f\"\\nTop-{TOP_K} popular items: {popular_items}\")\n",
    "print(f\"‚úÖ Cold-start fallback ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### ÏòàÏ∏° ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Generating Predictions\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f675ceadb9846e3881140abeb888078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/8482 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Predictions generated\n",
      "   Total users: 8,482\n",
      "   Cold-start: 0\n",
      "======================================================================\n",
      "CPU times: user 3.36 s, sys: 121 ms, total: 3.48 s\n",
      "Wall time: 3.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Generating Predictions\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_users = list(full_dataset.uid_map.keys())\n",
    "predictions = {}\n",
    "cold_start_count = 0\n",
    "\n",
    "for user_id in tqdm(all_users, desc=\"Predicting\"):\n",
    "    try:\n",
    "        recs = final_model.recommend(user_id, k=TOP_K)\n",
    "        predictions[user_id] = recs\n",
    "    except:\n",
    "        predictions[user_id] = popular_items\n",
    "        cold_start_count += 1\n",
    "\n",
    "print(f\"\\n‚úÖ Predictions generated\")\n",
    "print(f\"   Total users: {len(predictions):,}\")\n",
    "print(f\"   Cold-start: {cold_start_count:,}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "### Ï†úÏ∂ú ÌååÏùº ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Creating Submission File\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Submission saved: outputs/2025-11-19/submit_EASE_lambda100_20251119154249.csv\n",
      "   Recommendations: 42,410\n",
      "   Users: 8,482\n",
      "======================================================================\n",
      "CPU times: user 34.5 ms, sys: 4.7 ms, total: 39.2 ms\n",
      "Wall time: 38.4 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_seq</th>\n",
       "      <th>recruitment_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R00999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R00585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R01455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R03978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U05833</td>\n",
       "      <td>R00304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R00446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R00421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R00697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R06530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U06456</td>\n",
       "      <td>R04578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  resume_seq recruitment_seq\n",
       "0     U05833          R00999\n",
       "1     U05833          R00585\n",
       "2     U05833          R01455\n",
       "3     U05833          R03978\n",
       "4     U05833          R00304\n",
       "5     U06456          R00446\n",
       "6     U06456          R00421\n",
       "7     U06456          R00697\n",
       "8     U06456          R06530\n",
       "9     U06456          R04578"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Creating Submission File\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "submission = []\n",
    "for user_id, items in predictions.items():\n",
    "    for item_id in items:\n",
    "        submission.append({\n",
    "            DEFAULT_USER_COL: user_id,\n",
    "            DEFAULT_ITEM_COL: item_id\n",
    "        })\n",
    "\n",
    "df_submission = pd.DataFrame(submission)\n",
    "\n",
    "# Create output directory with current date\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "output_dir = f'outputs/{current_date}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate filename with full timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "filename = f\"{output_dir}/submit_EASE_lambda{EASE_LAMBDA}_{timestamp}.csv\"\n",
    "df_submission.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Submission saved: {filename}\")\n",
    "print(f\"   Recommendations: {len(df_submission):,}\")\n",
    "print(f\"   Users: {df_submission[DEFAULT_USER_COL].nunique():,}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### ÏöîÏïΩ (Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EASE Model Summary\n",
      "======================================================================\n",
      "\n",
      "üìö Paper: Steck, 2019 - WWW Conference\n",
      "\n",
      "‚öôÔ∏è Configuration:\n",
      "   Lambda (Œª): 100\n",
      "   Tuning mode: fast\n",
      "   Device: mps\n",
      "   Seed: 202511\n",
      "\n",
      "üìä Dataset:\n",
      "   Users: 8,482\n",
      "   Items: 6,695\n",
      "   Interactions: 57,946\n",
      "   Sparsity: 99.9%\n",
      "\n",
      "üìÅ Output:\n",
      "   File: outputs/2025-11-19/submit_EASE_lambda100_20251119154249.csv\n",
      "   Cold-start users: 0\n",
      "\n",
      "üéØ Expected Performance:\n",
      "   Validation Recall@5: ~0.40 (temporal split)\n",
      "   Expected Public LB: 0.08-0.10\n",
      "   Expected Private LB: 0.09-0.11\n",
      "\n",
      "üí° Notes:\n",
      "   - EASE is a linear autoencoder (fast & interpretable)\n",
      "   - Œª=100 balances fit vs regularization\n",
      "   - Good baseline for sparse data (99.9%)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"EASE Model Summary\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìö Paper: Steck, 2019 - WWW Conference\")\n",
    "print(f\"\\n‚öôÔ∏è Configuration:\")\n",
    "print(f\"   Lambda (Œª): {EASE_LAMBDA}\")\n",
    "print(f\"   Tuning mode: {TUNING_MODE}\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Seed: {SEED}\")\n",
    "\n",
    "print(f\"\\nüìä Dataset:\")\n",
    "print(f\"   Users: {full_dataset.num_users:,}\")\n",
    "print(f\"   Items: {full_dataset.num_items:,}\")\n",
    "print(f\"   Interactions: {len(data):,}\")\n",
    "print(f\"   Sparsity: 99.9%\")\n",
    "\n",
    "print(f\"\\nüìÅ Output:\")\n",
    "print(f\"   File: {filename}\")\n",
    "print(f\"   Cold-start users: {cold_start_count:,}\")\n",
    "\n",
    "print(f\"\\nüéØ Expected Performance:\")\n",
    "print(f\"   Validation Recall@5: ~0.40 (temporal split)\")\n",
    "print(f\"   Expected Public LB: 0.08-0.10\")\n",
    "print(f\"   Expected Private LB: 0.09-0.11\")\n",
    "\n",
    "print(f\"\\nüí° Notes:\")\n",
    "print(f\"   - EASE is a linear autoencoder (fast & interpretable)\")\n",
    "print(f\"   - Œª={EASE_LAMBDA} balances fit vs regularization\")\n",
    "print(f\"   - Good baseline for sparse data (99.9%)\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cornac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
