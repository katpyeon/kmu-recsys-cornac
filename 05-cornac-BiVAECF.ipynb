{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiVAECF (Bilateral Variational Autoencoder for CF) - Ï∂îÏ≤ú ÏãúÏä§ÌÖú\n",
    "\n",
    "**ÎÖºÎ¨∏**: Truong et al., 2021 - \"Bilateral Variational Autoencoder for Collaborative Filtering\"  \n",
    "**Conference**: WSDM 2021\n",
    "\n",
    "## üìö Î™®Îç∏ ÏÑ§Î™Ö\n",
    "\n",
    "### ÌïµÏã¨ ÏïåÍ≥†Î¶¨Ï¶ò\n",
    "- **Bilateral VAE** - ÏÇ¨Ïö©ÏûêÏôÄ ÏïÑÏù¥ÌÖú ÏñëÎ∞©Ìñ• Ïû†Ïû¨ ÌëúÌòÑ ÌïôÏäµ\n",
    "- **Variational Inference** - ÌôïÎ•†Ï†Å ÏÉùÏÑ± Î™®Îç∏\n",
    "- **Bernoulli likelihood** - ÏïîÎ¨µÏ†Å ÌîºÎìúÎ∞± (ÌÅ¥Î¶≠/Íµ¨Îß§ Ïù¥Î†•)\n",
    "- **Deep learning** Í∏∞Î∞ò - GPU/MPS Í∞ÄÏÜç Í∞ÄÎä•\n",
    "\n",
    "## üéØ ÌïµÏã¨ Ï†ÑÎûµ\n",
    "\n",
    "### ÌäúÎãù Ï†ÑÎûµ (ÎÖºÎ¨∏ Í∏∞Î∞ò)\n",
    "1. **Fast Mode**: Í≤ÄÏ¶ùÎêú ÏµúÏ†Å ÌååÎùºÎØ∏ÌÑ∞ ÏÇ¨Ïö©\n",
    "   - k=100 (Ïû†Ïû¨ Ï∞®Ïõê)\n",
    "   - encoder=[100] (Îã®Ïùº ÌûàÎì† Î†àÏù¥Ïñ¥)\n",
    "   - likelihood='bern' (Bernoulli - ÏïîÎ¨µÏ†Å ÌîºÎìúÎ∞± ÌïÑÏàò)\n",
    "   - n_epochs=150\n",
    "   - batch_size=256\n",
    "\n",
    "2. **Thorough Mode**: Grid search\n",
    "   - k: [50, 100, 150]\n",
    "   - encoder_structure: [[50], [100], [200]]\n",
    "   - n_epochs: [150, 200]\n",
    "   - ÏÜåÏöî ÏãúÍ∞Ñ: ~20ÏãúÍ∞Ñ\n",
    "\n",
    "### Ïö∞Î¶¨ Îç∞Ïù¥ÌÑ∞ ÌäπÏÑ±\n",
    "- **Sparsity**: 99.9% (Îß§Ïö∞ ÎÜíÏùå - BiVAECFÏóê Î∂àÎ¶¨)\n",
    "- **Î¨∏Ï†úÏ†ê**: VAE Í≥ÑÏó¥ÏùÄ dense dataÏóêÏÑú ÏµúÏ†Å ÏÑ±Îä•\n",
    "- **Ï†ÑÎûµ**: Fast mode Í∂åÏû• (tuning Ìö®Í≥º ÎØ∏ÎØ∏)\n",
    "\n",
    "## üìä ÏòàÏÉÅ ÏÑ±Îä•\n",
    "\n",
    "- **Validation Recall@5**: ~0.03 (Îß§Ïö∞ ÎÇÆÏùå)\n",
    "- **Expected Public LB**: 0.02-0.03\n",
    "- **Expected Private LB**: 0.02-0.03\n",
    "\n",
    "‚ö†Ô∏è **Í≤ΩÍ≥†**: BiVAECFÎäî 99.9% sparse dataÏóêÏÑú EASE/BPRÎ≥¥Îã§ ÌòÑÏ†ÄÌûà ÎÇÆÏùÄ ÏÑ±Îä•\n",
    "- EASE: 0.08-0.10\n",
    "- BPR: 0.09-0.12\n",
    "- BiVAECF: 0.02-0.03\n",
    "\n",
    "## ‚è±Ô∏è ÏÜåÏöî ÏãúÍ∞Ñ\n",
    "\n",
    "- **Fast Mode**: ~15Î∂Ñ (150 epochs)\n",
    "- **Thorough Mode**: ~20ÏãúÍ∞Ñ (grid search)\n",
    "- **ÌïôÏäµ ÏÜçÎèÑ**: MPS/CUDA Í∞ÄÏÜç Í∞ÄÎä•\n",
    "\n",
    "## üí° ÏÇ¨Ïö© Í∂åÏû•ÏÇ¨Ìï≠\n",
    "\n",
    "### Îã®ÎèÖ Ï†úÏ∂ú: ‚ùå Í∂åÏû•ÌïòÏßÄ ÏïäÏùå\n",
    "- Sparse dataÏóêÏÑú ÏÑ±Îä• Ï†ÄÏ°∞\n",
    "- EASE/BPR ÏÇ¨Ïö© Í∂åÏû•\n",
    "\n",
    "### ÏïôÏÉÅÎ∏î ÏÇ¨Ïö©: ‚ñ≥ Ï†úÌïúÏ†Å\n",
    "- Îã§ÏñëÏÑ±ÏùÄ Ï†úÍ≥µÌïòÏßÄÎßå ÏÑ±Îä• Í∏∞Ïó¨ ÎØ∏ÎØ∏\n",
    "- EASE + BPR + ItemKNN Ï°∞Ìï©Ïù¥ Îçî Ìö®Í≥ºÏ†Å\n",
    "\n",
    "### Ïñ∏Ï†ú ÏÇ¨Ïö©ÌïòÎÇò?\n",
    "- Ïã§Ìóò Î™©Ï†Å (VAE Í≥ÑÏó¥ ÏÑ±Îä• ÌôïÏù∏)\n",
    "- Dense data ÌôòÍ≤Ω (Îã§Î•∏ Îç∞Ïù¥ÌÑ∞ÏÖã)\n",
    "- Ï∂©Î∂ÑÌïú Ïª¥Ìì®ÌåÖ ÏûêÏõê Î≥¥Ïú† Ïãú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cornac version: 2.3.5\n",
      "PyTorch version: 2.9.1+cu128\n"
     ]
    }
   ],
   "source": [
    "### ÎùºÏù¥Î∏åÎü¨Î¶¨ Î∂àÎü¨Ïò§Í∏∞\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "from cornac.data import Dataset\n",
    "from cornac.models import BiVAECF\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Cornac version: {__import__('cornac').__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÏÑ§Ï†ï (Configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Using CUDA GPU: NVIDIA GeForce RTX 5070 Laptop GPU\n",
      "\n",
      "Mode: FAST\n",
      "Seed: 202511\n",
      "Top-K: 5\n"
     ]
    }
   ],
   "source": [
    "# Device selection: CUDA > MPS > CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(f\"‚úì Using CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(\"‚úì Using Apple Silicon MPS\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"‚úì Using CPU\")\n",
    "\n",
    "# Global settings\n",
    "SEED = 202511\n",
    "TOP_K = 5\n",
    "DEFAULT_USER_COL = 'resume_seq'\n",
    "DEFAULT_ITEM_COL = 'recruitment_seq'\n",
    "DEFAULT_RATING_COL = 'rating'\n",
    "\n",
    "# Tuning mode: 'fast' (use validated params) or 'thorough' (grid search)\n",
    "TUNING_MODE = 'fast'  # Change to 'thorough' for comprehensive tuning\n",
    "\n",
    "print(f\"\\nMode: {TUNING_MODE.upper()}\")\n",
    "print(f\"Seed: {SEED}\")\n",
    "print(f\"Top-K: {TOP_K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Îç∞Ïù¥ÌÑ∞ Î°úÎî©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (57946, 3)\n",
      "Users: 8482\n",
      "Items: 6695\n",
      "Interactions: 57946\n",
      "Sparsity: 0.9990\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "data = pd.read_csv('datasets/apply_train.csv')\n",
    "data[DEFAULT_RATING_COL] = 1  # Implicit feedback\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Users: {data[DEFAULT_USER_COL].nunique()}\")\n",
    "print(f\"Items: {data[DEFAULT_ITEM_COL].nunique()}\")\n",
    "print(f\"Interactions: {len(data)}\")\n",
    "print(f\"Sparsity: {1 - len(data) / (data[DEFAULT_USER_COL].nunique() * data[DEFAULT_ITEM_COL].nunique()):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation Split (ÏãúÍ∞Ñ Í∏∞Î∞ò Î∂ÑÌï†)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 46190 (79.7%)\n",
      "Val size: 11756 (20.3%)\n",
      "\n",
      "Train set - Users: 8402, Items: 6692\n"
     ]
    }
   ],
   "source": [
    "# Temporal split: 20% of each user's interactions for validation\n",
    "val_data = data.groupby(DEFAULT_USER_COL, group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=0.2, random_state=SEED) if len(x) > 1 else x.sample(frac=0, random_state=SEED)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "train_data = data[~data.index.isin(val_data.index)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train size: {len(train_data)} ({len(train_data)/len(data)*100:.1f}%)\")\n",
    "print(f\"Val size: {len(val_data)} ({len(val_data)/len(data)*100:.1f}%)\")\n",
    "\n",
    "# Create Cornac dataset from train data only\n",
    "train_set = Dataset.from_uir(train_data.itertuples(index=False), seed=SEED)\n",
    "print(f\"\\nTrain set - Users: {train_set.num_users}, Items: {train_set.num_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Í≤ÄÏ¶ù Ìï®Ïàò (Validation Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recall_on_validation(model, train_set, val_data, k=TOP_K):\n",
    "    \"\"\"Calculate Recall@K on validation set\"\"\"\n",
    "    # Build validation ground truth\n",
    "    val_dict = {}\n",
    "    for _, row in val_data.iterrows():\n",
    "        user_id = row[DEFAULT_USER_COL]\n",
    "        item_id = row[DEFAULT_ITEM_COL]\n",
    "        if user_id not in val_dict:\n",
    "            val_dict[user_id] = set()\n",
    "        val_dict[user_id].add(item_id)\n",
    "    \n",
    "    # Calculate recall for each user\n",
    "    recall_scores = []\n",
    "    users_evaluated = 0\n",
    "    \n",
    "    for user_id, true_items in val_dict.items():\n",
    "        if user_id not in train_set.uid_map:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            recommended_items = model.recommend(user_id, k=k)\n",
    "            hits = len(set(recommended_items) & true_items)\n",
    "            recall = hits / len(true_items) if len(true_items) > 0 else 0.0\n",
    "            recall_scores.append(recall)\n",
    "            users_evaluated += 1\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    avg_recall = np.mean(recall_scores) if recall_scores else 0.0\n",
    "    print(f\"  Users evaluated: {users_evaluated}/{len(val_dict)}\")\n",
    "    \n",
    "    return avg_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiVAECF ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
    "\n",
    "**ÎÖºÎ¨∏ ÌïµÏã¨ ÏàòÏ†ïÏÇ¨Ìï≠ (Truong et al., 2021)**:\n",
    "- `likelihood='bern'`: ÏïîÎ¨µÏ†Å ÌîºÎìúÎ∞±ÏóêÎäî Bernoulli ÌïÑÏàò (NOT 'pois')\n",
    "- `k=100`: Î≥µÏû°Ìïú Ìå®ÌÑ¥ ÌïôÏäµÏùÑ ÏúÑÌïú ÌÅ∞ Ïû†Ïû¨ Ï∞®Ïõê\n",
    "- `n_epochs=150`: ÏàòÎ†¥ÏùÑ ÏúÑÌïú Ï∂©Î∂ÑÌïú ÏóêÌè≠ Ïàò\n",
    "- Capacity priors ÏóÜÏùå (ÏÇ¨Ïö©Ïûê/ÏïÑÏù¥ÌÖú ÌäπÏÑ± Îç∞Ïù¥ÌÑ∞ ÎØ∏Î≥¥Ïú†)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast Mode - Using optimized parameters:\n",
      "  k: 100\n",
      "  encoder_structure: [100]\n",
      "  act_fn: tanh\n",
      "  likelihood: bern\n",
      "  n_epochs: 150\n",
      "  batch_size: 256\n",
      "  learning_rate: 0.001\n",
      "  beta_kl: 0.5\n"
     ]
    }
   ],
   "source": [
    "if TUNING_MODE == 'fast':\n",
    "    # Fast Mode: Optimized parameters from research\n",
    "    BiVAECF_PARAMS = {\n",
    "        'k': 100,  # Latent dimension (increased from previous k=20)\n",
    "        'encoder_structure': [100],  # Single hidden layer\n",
    "        'act_fn': 'tanh',  # Activation function\n",
    "        'likelihood': 'bern',  # CRITICAL: Bernoulli for implicit feedback\n",
    "        'n_epochs': 150,  # Increased from 100\n",
    "        'batch_size': 256,  # Larger batch for stability\n",
    "        'learning_rate': 0.001,\n",
    "        'beta_kl': 0.5  # KL divergence weight\n",
    "    }\n",
    "    \n",
    "    print(\"Fast Mode - Using optimized parameters:\")\n",
    "    for k, v in BiVAECF_PARAMS.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "else:\n",
    "    # Thorough Mode: Grid search parameter space\n",
    "    PARAM_GRID = {\n",
    "        'k': [50, 100, 150],\n",
    "        'encoder_structure': [[50], [100], [200]],\n",
    "        'likelihood': ['bern'],  # Fixed to Bernoulli\n",
    "        'n_epochs': [150, 200],\n",
    "        'batch_size': [128, 256],\n",
    "        'learning_rate': [0.001, 0.005],\n",
    "        'beta_kl': [0.3, 0.5, 0.7]\n",
    "    }\n",
    "    \n",
    "    print(\"Thorough Mode - Grid search space:\")\n",
    "    for k, v in PARAM_GRID.items():\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Î™®Îç∏ ÌïôÏäµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training BiVAECF with validated parameters...\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d9092a0289453bae1769a35f0b3d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Users evaluated: 6712/6727\n",
      "\n",
      "Validation Recall@5: 0.0472\n",
      "\n",
      "============================================================\n",
      "Model training complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if TUNING_MODE == 'fast':\n",
    "    # Fast Mode: Train with validated parameters\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Training BiVAECF with validated parameters...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    model = BiVAECF(\n",
    "        k=BiVAECF_PARAMS['k'],\n",
    "        encoder_structure=BiVAECF_PARAMS['encoder_structure'],\n",
    "        act_fn=BiVAECF_PARAMS['act_fn'],\n",
    "        likelihood=BiVAECF_PARAMS['likelihood'],\n",
    "        n_epochs=BiVAECF_PARAMS['n_epochs'],\n",
    "        batch_size=BiVAECF_PARAMS['batch_size'],\n",
    "        learning_rate=BiVAECF_PARAMS['learning_rate'],\n",
    "        beta_kl=BiVAECF_PARAMS['beta_kl'],\n",
    "        seed=SEED,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    model.fit(train_set)\n",
    "    \n",
    "    # Validation\n",
    "    val_recall = evaluate_recall_on_validation(model, train_set, val_data)\n",
    "    print(f\"\\nValidation Recall@{TOP_K}: {val_recall:.4f}\")\n",
    "    \n",
    "    best_model = model\n",
    "    best_params = BiVAECF_PARAMS\n",
    "    best_recall = val_recall\n",
    "\n",
    "else:\n",
    "    # Thorough Mode: Grid search\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Starting Grid Search for BiVAECF...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    from itertools import product\n",
    "    \n",
    "    # Generate all combinations\n",
    "    param_combinations = list(product(\n",
    "        PARAM_GRID['k'],\n",
    "        PARAM_GRID['encoder_structure'],\n",
    "        PARAM_GRID['likelihood'],\n",
    "        PARAM_GRID['n_epochs'],\n",
    "        PARAM_GRID['batch_size'],\n",
    "        PARAM_GRID['learning_rate'],\n",
    "        PARAM_GRID['beta_kl']\n",
    "    ))\n",
    "    \n",
    "    print(f\"Total combinations: {len(param_combinations)}\")\n",
    "    print(f\"Estimated time: {len(param_combinations) * 20 / 60:.1f} hours\\n\")\n",
    "    \n",
    "    best_recall = 0\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, (k, enc_struct, likelihood, n_epochs, batch_size, lr, beta_kl) in enumerate(param_combinations, 1):\n",
    "        print(f\"\\n[{i}/{len(param_combinations)}] Testing: k={k}, enc={enc_struct}, epochs={n_epochs}, bs={batch_size}, lr={lr}, beta={beta_kl}\")\n",
    "        \n",
    "        try:\n",
    "            model = BiVAECF(\n",
    "                k=k,\n",
    "                encoder_structure=enc_struct,\n",
    "                act_fn='tanh',\n",
    "                likelihood=likelihood,\n",
    "                n_epochs=n_epochs,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=lr,\n",
    "                beta_kl=beta_kl,\n",
    "                seed=SEED,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            model.fit(train_set)\n",
    "            recall = evaluate_recall_on_validation(model, train_set, val_data)\n",
    "            \n",
    "            print(f\"  Recall@{TOP_K}: {recall:.4f}\")\n",
    "            \n",
    "            results.append({\n",
    "                'k': k,\n",
    "                'encoder_structure': enc_struct,\n",
    "                'n_epochs': n_epochs,\n",
    "                'batch_size': batch_size,\n",
    "                'learning_rate': lr,\n",
    "                'beta_kl': beta_kl,\n",
    "                'recall': recall\n",
    "            })\n",
    "            \n",
    "            if recall > best_recall:\n",
    "                best_recall = recall\n",
    "                best_params = {\n",
    "                    'k': k,\n",
    "                    'encoder_structure': enc_struct,\n",
    "                    'likelihood': likelihood,\n",
    "                    'n_epochs': n_epochs,\n",
    "                    'batch_size': batch_size,\n",
    "                    'learning_rate': lr,\n",
    "                    'beta_kl': beta_kl\n",
    "                }\n",
    "                best_model = model\n",
    "                print(f\"  ‚òÖ New best! Recall@{TOP_K}: {best_recall:.4f}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Print results summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Grid Search Results Summary\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('recall', ascending=False)\n",
    "    print(results_df.head(10).to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nBest parameters:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(f\"Best Recall@{TOP_K}: {best_recall:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Model training complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î°ú ÏµúÏ¢Ö Î™®Îç∏ Ïû¨ÌïôÏäµ\n",
    "\n",
    "ÏµúÏ†Å ÌååÎùºÎØ∏ÌÑ∞Î°ú Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÏÖã Ïû¨ÌïôÏäµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Retraining BiVAECF on full dataset...\n",
      "============================================================\n",
      "Full dataset - Users: 8482, Items: 6695\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8725696b1dc453897fcc3ffa184d5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final model training complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Retraining BiVAECF on full dataset...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create full dataset\n",
    "full_train_set = Dataset.from_uir(data.itertuples(index=False), seed=SEED)\n",
    "print(f\"Full dataset - Users: {full_train_set.num_users}, Items: {full_train_set.num_items}\")\n",
    "\n",
    "# Retrain with best parameters\n",
    "final_model = BiVAECF(\n",
    "    k=best_params['k'],\n",
    "    encoder_structure=best_params['encoder_structure'],\n",
    "    act_fn='tanh',\n",
    "    likelihood=best_params['likelihood'],\n",
    "    n_epochs=best_params['n_epochs'],\n",
    "    batch_size=best_params['batch_size'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    beta_kl=best_params['beta_kl'],\n",
    "    seed=SEED,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "final_model.fit(full_train_set)\n",
    "\n",
    "print(\"\\nFinal model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cold-Start Ï≤òÎ¶¨ Ìè¨Ìï® ÏòàÏ∏° ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Generating predictions...\n",
      "============================================================\n",
      "Total users: 8482\n",
      "Popular items for cold-start: ['R03237', 'R01214', 'R00056', 'R00773', 'R00944']\n",
      "\n",
      "Predictions generated: 42410\n",
      "Cold-start users: 0/8482 (0.0%)\n",
      "\n",
      "Submission shape: (42410, 2)\n",
      "Expected: (42410, 2)\n",
      "‚úì All users have exactly 5 recommendations\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating predictions...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get all unique users from training data\n",
    "all_users = data[DEFAULT_USER_COL].unique()\n",
    "print(f\"Total users: {len(all_users)}\")\n",
    "\n",
    "# Calculate item popularity for cold-start fallback\n",
    "item_popularity = data[DEFAULT_ITEM_COL].value_counts().head(TOP_K).index.tolist()\n",
    "print(f\"Popular items for cold-start: {item_popularity[:5]}\")\n",
    "\n",
    "# Generate predictions\n",
    "predictions = []\n",
    "cold_start_count = 0\n",
    "\n",
    "for user_id in all_users:\n",
    "    if user_id in full_train_set.uid_map:\n",
    "        try:\n",
    "            recommended_items = final_model.recommend(user_id, k=TOP_K)\n",
    "            \n",
    "            # Ensure we have exactly TOP_K recommendations\n",
    "            if len(recommended_items) < TOP_K:\n",
    "                # Pad with popular items\n",
    "                for item in item_popularity:\n",
    "                    if item not in recommended_items:\n",
    "                        recommended_items.append(item)\n",
    "                    if len(recommended_items) >= TOP_K:\n",
    "                        break\n",
    "            \n",
    "            for item_id in recommended_items[:TOP_K]:\n",
    "                predictions.append({\n",
    "                    DEFAULT_USER_COL: user_id,\n",
    "                    DEFAULT_ITEM_COL: item_id\n",
    "                })\n",
    "        except:\n",
    "            # Cold-start fallback\n",
    "            for item_id in item_popularity[:TOP_K]:\n",
    "                predictions.append({\n",
    "                    DEFAULT_USER_COL: user_id,\n",
    "                    DEFAULT_ITEM_COL: item_id\n",
    "                })\n",
    "            cold_start_count += 1\n",
    "    else:\n",
    "        # Cold-start fallback\n",
    "        for item_id in item_popularity[:TOP_K]:\n",
    "            predictions.append({\n",
    "                DEFAULT_USER_COL: user_id,\n",
    "                DEFAULT_ITEM_COL: item_id\n",
    "            })\n",
    "        cold_start_count += 1\n",
    "\n",
    "print(f\"\\nPredictions generated: {len(predictions)}\")\n",
    "print(f\"Cold-start users: {cold_start_count}/{len(all_users)} ({cold_start_count/len(all_users)*100:.1f}%)\")\n",
    "\n",
    "# Verify predictions\n",
    "submit_df = pd.DataFrame(predictions)\n",
    "print(f\"\\nSubmission shape: {submit_df.shape}\")\n",
    "print(f\"Expected: ({len(all_users) * TOP_K}, 2)\")\n",
    "\n",
    "# Check if all users have exactly TOP_K recommendations\n",
    "user_counts = submit_df[DEFAULT_USER_COL].value_counts()\n",
    "if (user_counts == TOP_K).all():\n",
    "    print(f\"‚úì All users have exactly {TOP_K} recommendations\")\n",
    "else:\n",
    "    print(f\"‚úó Warning: Some users have != {TOP_K} recommendations\")\n",
    "    print(user_counts[user_counts != TOP_K])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ï†úÏ∂ú ÌååÏùº Ï†ÄÏû•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Submission file saved!\n",
      "============================================================\n",
      "Filename: outputs/2025-11-20/submit_BiVAECF_k100_epochs150_20251120110511.csv\n",
      "Shape: (42410, 2)\n",
      "\n",
      "Best parameters used:\n",
      "  k: 100\n",
      "  encoder_structure: [100]\n",
      "  act_fn: tanh\n",
      "  likelihood: bern\n",
      "  n_epochs: 150\n",
      "  batch_size: 256\n",
      "  learning_rate: 0.001\n",
      "  beta_kl: 0.5\n",
      "\n",
      "Validation Recall@5: 0.0472\n",
      "Expected Public LB: 0.02-0.03 (significantly lower due to validation-test gap)\n",
      "\n",
      "‚ö†Ô∏è  Note: BiVAECF may underperform on 99.9% sparse data compared to EASE/BPR\n"
     ]
    }
   ],
   "source": [
    "# Create output directory with current date\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "output_dir = f'outputs/{current_date}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate filename with full timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "param_str = f\"k{best_params['k']}_epochs{best_params['n_epochs']}\"\n",
    "filename = f\"{output_dir}/submit_BiVAECF_{param_str}_{timestamp}.csv\"\n",
    "\n",
    "# Save\n",
    "submit_df.to_csv(filename, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Submission file saved!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Filename: {filename}\")\n",
    "print(f\"Shape: {submit_df.shape}\")\n",
    "print(f\"\\nBest parameters used:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"\\nValidation Recall@{TOP_K}: {best_recall:.4f}\")\n",
    "print(f\"Expected Public LB: 0.02-0.03 (significantly lower due to validation-test gap)\")\n",
    "print(\"\\n‚ö†Ô∏è  Note: BiVAECF may underperform on 99.9% sparse data compared to EASE/BPR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÏÑ±Îä• ÏöîÏïΩ (Performance Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BiVAECF PERFORMANCE SUMMARY\n",
      "============================================================\n",
      "\n",
      "Model: BiVAECF\n",
      "Mode: FAST\n",
      "\n",
      "Best Parameters:\n",
      "  k: 100\n",
      "  encoder_structure: [100]\n",
      "  act_fn: tanh\n",
      "  likelihood: bern\n",
      "  n_epochs: 150\n",
      "  batch_size: 256\n",
      "  learning_rate: 0.001\n",
      "  beta_kl: 0.5\n",
      "\n",
      "Validation Recall@5: 0.0472\n",
      "Expected Public LB: 0.02-0.03\n",
      "Expected Private LB: 0.02-0.03\n",
      "\n",
      "Submission file: outputs/2025-11-20/submit_BiVAECF_k100_epochs150_20251120110511.csv\n",
      "Total predictions: 42410\n",
      "Cold-start users: 0 (0.0%)\n",
      "\n",
      "============================================================\n",
      "Recommendation: Compare with EASE (0.08-0.10) and BPR (0.09-0.12)\n",
      "BiVAECF is expected to perform worse due to extreme data sparsity.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BiVAECF PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModel: BiVAECF\")\n",
    "print(f\"Mode: {TUNING_MODE.upper()}\")\n",
    "print(f\"\\nBest Parameters:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"\\nValidation Recall@{TOP_K}: {best_recall:.4f}\")\n",
    "print(f\"Expected Public LB: 0.02-0.03\")\n",
    "print(f\"Expected Private LB: 0.02-0.03\")\n",
    "print(f\"\\nSubmission file: {filename}\")\n",
    "print(f\"Total predictions: {len(submit_df)}\")\n",
    "print(f\"Cold-start users: {cold_start_count} ({cold_start_count/len(all_users)*100:.1f}%)\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Recommendation: Compare with EASE (0.08-0.10) and BPR (0.09-0.12)\")\n",
    "print(\"BiVAECF is expected to perform worse due to extreme data sparsity.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cornac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
