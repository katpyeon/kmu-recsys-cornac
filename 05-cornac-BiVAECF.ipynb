{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiVAECF (Bilateral Variational Autoencoder for CF) - Ï∂îÏ≤ú ÏãúÏä§ÌÖú\n",
    "\n",
    "**ÎÖºÎ¨∏**: Truong et al., 2021 - \"Bilateral Variational Autoencoder for Collaborative Filtering\"  \n",
    "**Conference**: WSDM 2021\n",
    "\n",
    "## üìö Î™®Îç∏ ÏÑ§Î™Ö\n",
    "\n",
    "### ÌïµÏã¨ ÏïåÍ≥†Î¶¨Ï¶ò\n",
    "- **Bilateral VAE** - ÏÇ¨Ïö©ÏûêÏôÄ ÏïÑÏù¥ÌÖú ÏñëÎ∞©Ìñ• Ïû†Ïû¨ ÌëúÌòÑ ÌïôÏäµ\n",
    "- **Variational Inference** - ÌôïÎ•†Ï†Å ÏÉùÏÑ± Î™®Îç∏\n",
    "- **Bernoulli likelihood** - ÏïîÎ¨µÏ†Å ÌîºÎìúÎ∞± (ÌÅ¥Î¶≠/Íµ¨Îß§ Ïù¥Î†•)\n",
    "- **Deep learning** Í∏∞Î∞ò - GPU/MPS Í∞ÄÏÜç Í∞ÄÎä•\n",
    "\n",
    "## üéØ ÌïµÏã¨ Ï†ÑÎûµ\n",
    "\n",
    "### ÌäúÎãù Ï†ÑÎûµ (ÎÖºÎ¨∏ Í∏∞Î∞ò)\n",
    "1. **Fast Mode**: Í≤ÄÏ¶ùÎêú ÏµúÏ†Å ÌååÎùºÎØ∏ÌÑ∞ ÏÇ¨Ïö©\n",
    "   - k=100 (Ïû†Ïû¨ Ï∞®Ïõê)\n",
    "   - encoder=[100] (Îã®Ïùº ÌûàÎì† Î†àÏù¥Ïñ¥)\n",
    "   - likelihood='bern' (Bernoulli - ÏïîÎ¨µÏ†Å ÌîºÎìúÎ∞± ÌïÑÏàò)\n",
    "   - n_epochs=150\n",
    "   - batch_size=256\n",
    "\n",
    "2. **Thorough Mode**: Grid search\n",
    "   - k: [50, 100, 150]\n",
    "   - encoder_structure: [[50], [100], [200]]\n",
    "   - n_epochs: [150, 200]\n",
    "   - ÏÜåÏöî ÏãúÍ∞Ñ: ~20ÏãúÍ∞Ñ\n",
    "\n",
    "### Ïö∞Î¶¨ Îç∞Ïù¥ÌÑ∞ ÌäπÏÑ±\n",
    "- **Sparsity**: 99.9% (Îß§Ïö∞ ÎÜíÏùå - BiVAECFÏóê Î∂àÎ¶¨)\n",
    "- **Î¨∏Ï†úÏ†ê**: VAE Í≥ÑÏó¥ÏùÄ dense dataÏóêÏÑú ÏµúÏ†Å ÏÑ±Îä•\n",
    "- **Ï†ÑÎûµ**: Fast mode Í∂åÏû• (tuning Ìö®Í≥º ÎØ∏ÎØ∏)\n",
    "\n",
    "## üìä ÏòàÏÉÅ ÏÑ±Îä•\n",
    "\n",
    "- **Validation Recall@5**: ~0.03 (Îß§Ïö∞ ÎÇÆÏùå)\n",
    "- **Expected Public LB**: 0.02-0.03\n",
    "- **Expected Private LB**: 0.02-0.03\n",
    "\n",
    "‚ö†Ô∏è **Í≤ΩÍ≥†**: BiVAECFÎäî 99.9% sparse dataÏóêÏÑú EASE/BPRÎ≥¥Îã§ ÌòÑÏ†ÄÌûà ÎÇÆÏùÄ ÏÑ±Îä•\n",
    "- EASE: 0.08-0.10\n",
    "- BPR: 0.09-0.12\n",
    "- BiVAECF: 0.02-0.03\n",
    "\n",
    "## ‚è±Ô∏è ÏÜåÏöî ÏãúÍ∞Ñ\n",
    "\n",
    "- **Fast Mode**: ~15Î∂Ñ (150 epochs)\n",
    "- **Thorough Mode**: ~20ÏãúÍ∞Ñ (grid search)\n",
    "- **ÌïôÏäµ ÏÜçÎèÑ**: MPS/CUDA Í∞ÄÏÜç Í∞ÄÎä•\n",
    "\n",
    "## üí° ÏÇ¨Ïö© Í∂åÏû•ÏÇ¨Ìï≠\n",
    "\n",
    "### Îã®ÎèÖ Ï†úÏ∂ú: ‚ùå Í∂åÏû•ÌïòÏßÄ ÏïäÏùå\n",
    "- Sparse dataÏóêÏÑú ÏÑ±Îä• Ï†ÄÏ°∞\n",
    "- EASE/BPR ÏÇ¨Ïö© Í∂åÏû•\n",
    "\n",
    "### ÏïôÏÉÅÎ∏î ÏÇ¨Ïö©: ‚ñ≥ Ï†úÌïúÏ†Å\n",
    "- Îã§ÏñëÏÑ±ÏùÄ Ï†úÍ≥µÌïòÏßÄÎßå ÏÑ±Îä• Í∏∞Ïó¨ ÎØ∏ÎØ∏\n",
    "- EASE + BPR + ItemKNN Ï°∞Ìï©Ïù¥ Îçî Ìö®Í≥ºÏ†Å\n",
    "\n",
    "### Ïñ∏Ï†ú ÏÇ¨Ïö©ÌïòÎÇò?\n",
    "- Ïã§Ìóò Î™©Ï†Å (VAE Í≥ÑÏó¥ ÏÑ±Îä• ÌôïÏù∏)\n",
    "- Dense data ÌôòÍ≤Ω (Îã§Î•∏ Îç∞Ïù¥ÌÑ∞ÏÖã)\n",
    "- Ï∂©Î∂ÑÌïú Ïª¥Ìì®ÌåÖ ÏûêÏõê Î≥¥Ïú† Ïãú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cornac version: 2.3.5\n",
      "PyTorch version: 2.9.1+cu128\n"
     ]
    }
   ],
   "source": [
    "### ÎùºÏù¥Î∏åÎü¨Î¶¨ Î∂àÎü¨Ïò§Í∏∞\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "from cornac.data import Dataset\n",
    "from cornac.models import BiVAECF\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Cornac version: {__import__('cornac').__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÏÑ§Ï†ï (Configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# ÎîîÎ∞îÏù¥Ïä§ ÏûêÎèô ÏÑ†ÌÉù Î∞è ÏµúÏ†ÅÌôî ÏÑ§Ï†ï\n# ============================================================\nprint(\"=\" * 60)\nprint(\"ÎîîÎ∞îÏù¥Ïä§ ÏÑ†ÌÉù Î∞è ÏµúÏ†ÅÌôî ÏÑ§Ï†ï\")\nprint(\"=\" * 60)\n\nif torch.cuda.is_available():\n    device = 'cuda'\n    total_cpus = os.cpu_count() or 4\n    print(f\"üöÄ ÎîîÎ∞îÏù¥Ïä§: CUDA ({torch.cuda.get_device_name(0)})\")\n    print(f\"   ÏÇ¨Ïö© Í∞ÄÎä• CPU: {total_cpus}ÏΩîÏñ¥\")\n    print(f\"   GPU Î©îÎ™®Î¶¨: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\nelif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n    device = 'mps'\n    total_cpus = os.cpu_count() or 4\n    print(f\"üçé ÎîîÎ∞îÏù¥Ïä§: MPS (Apple Silicon)\")\n    print(f\"   ÏÇ¨Ïö© Í∞ÄÎä• CPU: {total_cpus}ÏΩîÏñ¥\")\nelse:\n    device = 'cpu'\n    total_cpus = os.cpu_count() or 4\n    print(f\"üíª ÎîîÎ∞îÏù¥Ïä§: CPU\")\n    print(f\"   ÏÇ¨Ïö© Í∞ÄÎä• CPU: {total_cpus}ÏΩîÏñ¥\")\n\nprint(f\"PyTorch version: {torch.__version__}\\n\")\n\n# Global settings\nSEED = 202511\nTOP_K = 5\nDEFAULT_USER_COL = 'resume_seq'\nDEFAULT_ITEM_COL = 'recruitment_seq'\nDEFAULT_RATING_COL = 'rating'\n\n# Tuning mode: 'fast' (use validated params) or 'thorough' (grid search)\nTUNING_MODE = 'thorough'  # Change to 'thorough' for comprehensive tuning\n\nprint(f\"Mode: {TUNING_MODE.upper()}\")\nprint(f\"Seed: {SEED}\")\nprint(f\"Top-K: {TOP_K}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Îç∞Ïù¥ÌÑ∞ Î°úÎî©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (57946, 3)\n",
      "Users: 8482\n",
      "Items: 6695\n",
      "Interactions: 57946\n",
      "Sparsity: 0.9990\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "data = pd.read_csv('datasets/apply_train.csv')\n",
    "data[DEFAULT_RATING_COL] = 1  # Implicit feedback\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Users: {data[DEFAULT_USER_COL].nunique()}\")\n",
    "print(f\"Items: {data[DEFAULT_ITEM_COL].nunique()}\")\n",
    "print(f\"Interactions: {len(data)}\")\n",
    "print(f\"Sparsity: {1 - len(data) / (data[DEFAULT_USER_COL].nunique() * data[DEFAULT_ITEM_COL].nunique()):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation Split (ÏãúÍ∞Ñ Í∏∞Î∞ò Î∂ÑÌï†)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 46190 (79.7%)\n",
      "Val size: 11756 (20.3%)\n",
      "\n",
      "Train set - Users: 8402, Items: 6692\n"
     ]
    }
   ],
   "source": [
    "# Temporal split: 20% of each user's interactions for validation\n",
    "val_data = data.groupby(DEFAULT_USER_COL, group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=0.2, random_state=SEED) if len(x) > 1 else x.sample(frac=0, random_state=SEED)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "train_data = data[~data.index.isin(val_data.index)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train size: {len(train_data)} ({len(train_data)/len(data)*100:.1f}%)\")\n",
    "print(f\"Val size: {len(val_data)} ({len(val_data)/len(data)*100:.1f}%)\")\n",
    "\n",
    "# Create Cornac dataset from train data only\n",
    "train_set = Dataset.from_uir(train_data.itertuples(index=False), seed=SEED)\n",
    "print(f\"\\nTrain set - Users: {train_set.num_users}, Items: {train_set.num_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Í≤ÄÏ¶ù Ìï®Ïàò (Validation Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recall_on_validation(model, train_set, val_data, k=TOP_K):\n",
    "    \"\"\"Calculate Recall@K on validation set\"\"\"\n",
    "    # Build validation ground truth\n",
    "    val_dict = {}\n",
    "    for _, row in val_data.iterrows():\n",
    "        user_id = row[DEFAULT_USER_COL]\n",
    "        item_id = row[DEFAULT_ITEM_COL]\n",
    "        if user_id not in val_dict:\n",
    "            val_dict[user_id] = set()\n",
    "        val_dict[user_id].add(item_id)\n",
    "    \n",
    "    # Calculate recall for each user\n",
    "    recall_scores = []\n",
    "    users_evaluated = 0\n",
    "    \n",
    "    for user_id, true_items in val_dict.items():\n",
    "        if user_id not in train_set.uid_map:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            recommended_items = model.recommend(user_id, k=k)\n",
    "            hits = len(set(recommended_items) & true_items)\n",
    "            recall = hits / len(true_items) if len(true_items) > 0 else 0.0\n",
    "            recall_scores.append(recall)\n",
    "            users_evaluated += 1\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    avg_recall = np.mean(recall_scores) if recall_scores else 0.0\n",
    "    print(f\"  Users evaluated: {users_evaluated}/{len(val_dict)}\")\n",
    "    \n",
    "    return avg_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiVAECF ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
    "\n",
    "**ÎÖºÎ¨∏ ÌïµÏã¨ ÏàòÏ†ïÏÇ¨Ìï≠ (Truong et al., 2021)**:\n",
    "- `likelihood='bern'`: ÏïîÎ¨µÏ†Å ÌîºÎìúÎ∞±ÏóêÎäî Bernoulli ÌïÑÏàò (NOT 'pois')\n",
    "- `k=100`: Î≥µÏû°Ìïú Ìå®ÌÑ¥ ÌïôÏäµÏùÑ ÏúÑÌïú ÌÅ∞ Ïû†Ïû¨ Ï∞®Ïõê\n",
    "- `n_epochs=150`: ÏàòÎ†¥ÏùÑ ÏúÑÌïú Ï∂©Î∂ÑÌïú ÏóêÌè≠ Ïàò\n",
    "- Capacity priors ÏóÜÏùå (ÏÇ¨Ïö©Ïûê/ÏïÑÏù¥ÌÖú ÌäπÏÑ± Îç∞Ïù¥ÌÑ∞ ÎØ∏Î≥¥Ïú†)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# ÎîîÎ∞îÏù¥Ïä§Î≥Ñ Î∞∞Ïπò ÌÅ¨Í∏∞ ÏµúÏ†ÅÌôî (CUDA Í∞ÄÏÜç)\n# ============================================================\nif device == 'cuda':\n    # CUDA: GPU Î©îÎ™®Î¶¨ ÌôúÏö© ÏµúÎåÄÌôî\n    train_batch_size = 1024  # 256 ‚Üí 1024 (4Î∞∞ Ï¶ùÍ∞Ä)\n    print(f\"üéÆ CUDA Î∞∞Ïπò ÌÅ¨Í∏∞: {train_batch_size}\")\nelif device == 'mps':\n    # MPS: ÌÜµÌï© Î©îÎ™®Î¶¨ Í≥†Î†§\n    train_batch_size = 512  # Î≥¥ÏàòÏ†Å Ï†ëÍ∑º\n    print(f\"üçé MPS Î∞∞Ïπò ÌÅ¨Í∏∞: {train_batch_size}\")\nelse:\n    # CPU: Í∏∞Î≥∏Í∞í Ïú†ÏßÄ\n    train_batch_size = 256\n    print(f\"üíª CPU Î∞∞Ïπò ÌÅ¨Í∏∞: {train_batch_size}\")\n\nprint()\n\nif TUNING_MODE == 'fast':\n    # Fast Mode: Optimized parameters from research\n    BiVAECF_PARAMS = {\n        'k': 100,  # Latent dimension (increased from previous k=20)\n        'encoder_structure': [100],  # Single hidden layer\n        'act_fn': 'tanh',  # Activation function\n        'likelihood': 'bern',  # CRITICAL: Bernoulli for implicit feedback\n        'n_epochs': 150,  # Increased from 100\n        'batch_size': train_batch_size,  # ÎèôÏ†Å Î∞∞Ïπò ÌÅ¨Í∏∞\n        'learning_rate': 0.001,\n        'beta_kl': 0.5  # KL divergence weight\n    }\n    \n    print(\"Fast Mode - Using optimized parameters:\")\n    for k, v in BiVAECF_PARAMS.items():\n        print(f\"  {k}: {v}\")\n\nelse:\n    # Thorough Mode: Grid search parameter space\n    PARAM_GRID = {\n        'k': [50, 100, 150],\n        'encoder_structure': [[50], [100], [200]],\n        'likelihood': ['bern'],  # Fixed to Bernoulli\n        'n_epochs': [150, 200],\n        'batch_size': [train_batch_size],  # ÎèôÏ†Å Î∞∞Ïπò ÌÅ¨Í∏∞ ÏÇ¨Ïö©\n        'learning_rate': [0.001, 0.005],\n        'beta_kl': [0.3, 0.5, 0.7]\n    }\n    \n    print(\"Thorough Mode - Grid search space:\")\n    for k, v in PARAM_GRID.items():\n        print(f\"  {k}: {v}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Î™®Îç∏ ÌïôÏäµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting Grid Search for BiVAECF...\n",
      "============================================================\n",
      "Total combinations: 216\n",
      "Estimated time: 72.0 hours\n",
      "\n",
      "\n",
      "[1/216] Testing: k=50, enc=[50], epochs=150, bs=128, lr=0.001, beta=0.3\n",
      "  Users evaluated: 6712/6727\n",
      "  Recall@5: 0.2610\n",
      "  ‚òÖ New best! Recall@5: 0.2610\n",
      "\n",
      "[2/216] Testing: k=50, enc=[50], epochs=150, bs=128, lr=0.001, beta=0.5\n",
      "  Users evaluated: 6712/6727\n",
      "  Recall@5: 0.1469\n",
      "\n",
      "[3/216] Testing: k=50, enc=[50], epochs=150, bs=128, lr=0.001, beta=0.7\n",
      "  Users evaluated: 6712/6727\n",
      "  Recall@5: 0.0877\n",
      "\n",
      "[4/216] Testing: k=50, enc=[50], epochs=150, bs=128, lr=0.005, beta=0.3\n",
      "  Users evaluated: 6712/6727\n",
      "  Recall@5: 0.5497\n",
      "  ‚òÖ New best! Recall@5: 0.5497\n",
      "\n",
      "[5/216] Testing: k=50, enc=[50], epochs=150, bs=128, lr=0.005, beta=0.5\n",
      "  Users evaluated: 6712/6727\n",
      "  Recall@5: 0.5017\n",
      "\n",
      "[6/216] Testing: k=50, enc=[50], epochs=150, bs=128, lr=0.005, beta=0.7\n",
      "  Users evaluated: 6712/6727\n",
      "  Recall@5: 0.3918\n",
      "\n",
      "[7/216] Testing: k=50, enc=[50], epochs=150, bs=256, lr=0.001, beta=0.3\n",
      "  Users evaluated: 6712/6727\n",
      "  Recall@5: 0.0210\n",
      "\n",
      "[8/216] Testing: k=50, enc=[50], epochs=150, bs=256, lr=0.001, beta=0.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     model = BiVAECF(\n\u001b[32m     63\u001b[39m         k=k,\n\u001b[32m     64\u001b[39m         encoder_structure=enc_struct,\n\u001b[32m   (...)\u001b[39m\u001b[32m     72\u001b[39m         verbose=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     73\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     recall = evaluate_recall_on_validation(model, train_set, val_data)\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Recall@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTOP_K\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/cornac/lib/python3.12/site-packages/cornac/models/bivaecf/recom_bivaecf.py:178\u001b[39m, in \u001b[36mBiVAECF.fit\u001b[39m\u001b[34m(self, train_set, val_set)\u001b[39m\n\u001b[32m    166\u001b[39m         num_users = train_set.matrix.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    167\u001b[39m         \u001b[38;5;28mself\u001b[39m.bivae = BiVAE(\n\u001b[32m    168\u001b[39m             k=\u001b[38;5;28mself\u001b[39m.k,\n\u001b[32m    169\u001b[39m             user_encoder_structure=[num_items] + \u001b[38;5;28mself\u001b[39m.encoder_structure,\n\u001b[32m   (...)\u001b[39m\u001b[32m    175\u001b[39m             batch_size=\u001b[38;5;28mself\u001b[39m.batch_size,\n\u001b[32m    176\u001b[39m         ).to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     \u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbivae\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearn_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta_kl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbeta_kl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n\u001b[32m    189\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m is trained already (trainable = False)\u001b[39m\u001b[33m\"\u001b[39m % (\u001b[38;5;28mself\u001b[39m.name))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/cornac/lib/python3.12/site-packages/cornac/models/bivaecf/bivae.py:231\u001b[39m, in \u001b[36mlearn\u001b[39m\u001b[34m(bivae, train_set, n_epochs, batch_size, learn_rate, beta_kl, verbose, device, dtype)\u001b[39m\n\u001b[32m    229\u001b[39m u_batch = x[u_ids, :]\n\u001b[32m    230\u001b[39m u_batch = u_batch.toarray()\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m u_batch = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[38;5;66;03m# Reconstructed batch\u001b[39;00m\n\u001b[32m    234\u001b[39m theta, u_batch_, u_mu, u_std = bivae(u_batch, user=\u001b[38;5;28;01mTrue\u001b[39;00m, beta=bivae.beta)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if TUNING_MODE == 'fast':\n",
    "    # Fast Mode: Train with validated parameters\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Training BiVAECF with validated parameters...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    model = BiVAECF(\n",
    "        k=BiVAECF_PARAMS['k'],\n",
    "        encoder_structure=BiVAECF_PARAMS['encoder_structure'],\n",
    "        act_fn=BiVAECF_PARAMS['act_fn'],\n",
    "        likelihood=BiVAECF_PARAMS['likelihood'],\n",
    "        n_epochs=BiVAECF_PARAMS['n_epochs'],\n",
    "        batch_size=BiVAECF_PARAMS['batch_size'],\n",
    "        learning_rate=BiVAECF_PARAMS['learning_rate'],\n",
    "        beta_kl=BiVAECF_PARAMS['beta_kl'],\n",
    "        seed=SEED,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    model.fit(train_set)\n",
    "    \n",
    "    # Validation\n",
    "    val_recall = evaluate_recall_on_validation(model, train_set, val_data)\n",
    "    print(f\"\\nValidation Recall@{TOP_K}: {val_recall:.4f}\")\n",
    "    \n",
    "    best_model = model\n",
    "    best_params = BiVAECF_PARAMS\n",
    "    best_recall = val_recall\n",
    "\n",
    "else:\n",
    "    # Thorough Mode: Grid search\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Starting Grid Search for BiVAECF...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    from itertools import product\n",
    "    \n",
    "    # Generate all combinations\n",
    "    param_combinations = list(product(\n",
    "        PARAM_GRID['k'],\n",
    "        PARAM_GRID['encoder_structure'],\n",
    "        PARAM_GRID['likelihood'],\n",
    "        PARAM_GRID['n_epochs'],\n",
    "        PARAM_GRID['batch_size'],\n",
    "        PARAM_GRID['learning_rate'],\n",
    "        PARAM_GRID['beta_kl']\n",
    "    ))\n",
    "    \n",
    "    print(f\"Total combinations: {len(param_combinations)}\")\n",
    "    print(f\"Estimated time: {len(param_combinations) * 20 / 60:.1f} hours\\n\")\n",
    "    \n",
    "    best_recall = 0\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, (k, enc_struct, likelihood, n_epochs, batch_size, lr, beta_kl) in enumerate(param_combinations, 1):\n",
    "        print(f\"\\n[{i}/{len(param_combinations)}] Testing: k={k}, enc={enc_struct}, epochs={n_epochs}, bs={batch_size}, lr={lr}, beta={beta_kl}\")\n",
    "        \n",
    "        try:\n",
    "            model = BiVAECF(\n",
    "                k=k,\n",
    "                encoder_structure=enc_struct,\n",
    "                act_fn='tanh',\n",
    "                likelihood=likelihood,\n",
    "                n_epochs=n_epochs,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=lr,\n",
    "                beta_kl=beta_kl,\n",
    "                seed=SEED,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            model.fit(train_set)\n",
    "            recall = evaluate_recall_on_validation(model, train_set, val_data)\n",
    "            \n",
    "            print(f\"  Recall@{TOP_K}: {recall:.4f}\")\n",
    "            \n",
    "            results.append({\n",
    "                'k': k,\n",
    "                'encoder_structure': enc_struct,\n",
    "                'n_epochs': n_epochs,\n",
    "                'batch_size': batch_size,\n",
    "                'learning_rate': lr,\n",
    "                'beta_kl': beta_kl,\n",
    "                'recall': recall\n",
    "            })\n",
    "            \n",
    "            if recall > best_recall:\n",
    "                best_recall = recall\n",
    "                best_params = {\n",
    "                    'k': k,\n",
    "                    'encoder_structure': enc_struct,\n",
    "                    'likelihood': likelihood,\n",
    "                    'n_epochs': n_epochs,\n",
    "                    'batch_size': batch_size,\n",
    "                    'learning_rate': lr,\n",
    "                    'beta_kl': beta_kl\n",
    "                }\n",
    "                best_model = model\n",
    "                print(f\"  ‚òÖ New best! Recall@{TOP_K}: {best_recall:.4f}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Print results summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Grid Search Results Summary\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('recall', ascending=False)\n",
    "    print(results_df.head(10).to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nBest parameters:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(f\"Best Recall@{TOP_K}: {best_recall:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Model training complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î°ú ÏµúÏ¢Ö Î™®Îç∏ Ïû¨ÌïôÏäµ\n",
    "\n",
    "ÏµúÏ†Å ÌååÎùºÎØ∏ÌÑ∞Î°ú Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÏÖã Ïû¨ÌïôÏäµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Retraining BiVAECF on full dataset...\n",
      "============================================================\n",
      "Full dataset - Users: 8482, Items: 6695\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8725696b1dc453897fcc3ffa184d5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final model training complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Retraining BiVAECF on full dataset...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create full dataset\n",
    "full_train_set = Dataset.from_uir(data.itertuples(index=False), seed=SEED)\n",
    "print(f\"Full dataset - Users: {full_train_set.num_users}, Items: {full_train_set.num_items}\")\n",
    "\n",
    "# Retrain with best parameters\n",
    "final_model = BiVAECF(\n",
    "    k=best_params['k'],\n",
    "    encoder_structure=best_params['encoder_structure'],\n",
    "    act_fn='tanh',\n",
    "    likelihood=best_params['likelihood'],\n",
    "    n_epochs=best_params['n_epochs'],\n",
    "    batch_size=best_params['batch_size'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    beta_kl=best_params['beta_kl'],\n",
    "    seed=SEED,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "final_model.fit(full_train_set)\n",
    "\n",
    "print(\"\\nFinal model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cold-Start Ï≤òÎ¶¨ Ìè¨Ìï® ÏòàÏ∏° ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Generating predictions...\n",
      "============================================================\n",
      "Total users: 8482\n",
      "Popular items for cold-start: ['R03237', 'R01214', 'R00056', 'R00773', 'R00944']\n",
      "\n",
      "Predictions generated: 42410\n",
      "Cold-start users: 0/8482 (0.0%)\n",
      "\n",
      "Submission shape: (42410, 2)\n",
      "Expected: (42410, 2)\n",
      "‚úì All users have exactly 5 recommendations\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating predictions...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get all unique users from training data\n",
    "all_users = data[DEFAULT_USER_COL].unique()\n",
    "print(f\"Total users: {len(all_users)}\")\n",
    "\n",
    "# Calculate item popularity for cold-start fallback\n",
    "item_popularity = data[DEFAULT_ITEM_COL].value_counts().head(TOP_K).index.tolist()\n",
    "print(f\"Popular items for cold-start: {item_popularity[:5]}\")\n",
    "\n",
    "# Generate predictions\n",
    "predictions = []\n",
    "cold_start_count = 0\n",
    "\n",
    "for user_id in all_users:\n",
    "    if user_id in full_train_set.uid_map:\n",
    "        try:\n",
    "            recommended_items = final_model.recommend(user_id, k=TOP_K)\n",
    "            \n",
    "            # Ensure we have exactly TOP_K recommendations\n",
    "            if len(recommended_items) < TOP_K:\n",
    "                # Pad with popular items\n",
    "                for item in item_popularity:\n",
    "                    if item not in recommended_items:\n",
    "                        recommended_items.append(item)\n",
    "                    if len(recommended_items) >= TOP_K:\n",
    "                        break\n",
    "            \n",
    "            for item_id in recommended_items[:TOP_K]:\n",
    "                predictions.append({\n",
    "                    DEFAULT_USER_COL: user_id,\n",
    "                    DEFAULT_ITEM_COL: item_id\n",
    "                })\n",
    "        except:\n",
    "            # Cold-start fallback\n",
    "            for item_id in item_popularity[:TOP_K]:\n",
    "                predictions.append({\n",
    "                    DEFAULT_USER_COL: user_id,\n",
    "                    DEFAULT_ITEM_COL: item_id\n",
    "                })\n",
    "            cold_start_count += 1\n",
    "    else:\n",
    "        # Cold-start fallback\n",
    "        for item_id in item_popularity[:TOP_K]:\n",
    "            predictions.append({\n",
    "                DEFAULT_USER_COL: user_id,\n",
    "                DEFAULT_ITEM_COL: item_id\n",
    "            })\n",
    "        cold_start_count += 1\n",
    "\n",
    "print(f\"\\nPredictions generated: {len(predictions)}\")\n",
    "print(f\"Cold-start users: {cold_start_count}/{len(all_users)} ({cold_start_count/len(all_users)*100:.1f}%)\")\n",
    "\n",
    "# Verify predictions\n",
    "submit_df = pd.DataFrame(predictions)\n",
    "print(f\"\\nSubmission shape: {submit_df.shape}\")\n",
    "print(f\"Expected: ({len(all_users) * TOP_K}, 2)\")\n",
    "\n",
    "# Check if all users have exactly TOP_K recommendations\n",
    "user_counts = submit_df[DEFAULT_USER_COL].value_counts()\n",
    "if (user_counts == TOP_K).all():\n",
    "    print(f\"‚úì All users have exactly {TOP_K} recommendations\")\n",
    "else:\n",
    "    print(f\"‚úó Warning: Some users have != {TOP_K} recommendations\")\n",
    "    print(user_counts[user_counts != TOP_K])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ï†úÏ∂ú ÌååÏùº Ï†ÄÏû•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Submission file saved!\n",
      "============================================================\n",
      "Filename: outputs/2025-11-20/submit_BiVAECF_k100_epochs150_20251120110511.csv\n",
      "Shape: (42410, 2)\n",
      "\n",
      "Best parameters used:\n",
      "  k: 100\n",
      "  encoder_structure: [100]\n",
      "  act_fn: tanh\n",
      "  likelihood: bern\n",
      "  n_epochs: 150\n",
      "  batch_size: 256\n",
      "  learning_rate: 0.001\n",
      "  beta_kl: 0.5\n",
      "\n",
      "Validation Recall@5: 0.0472\n",
      "Expected Public LB: 0.02-0.03 (significantly lower due to validation-test gap)\n",
      "\n",
      "‚ö†Ô∏è  Note: BiVAECF may underperform on 99.9% sparse data compared to EASE/BPR\n"
     ]
    }
   ],
   "source": [
    "# Create output directory with current date\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "output_dir = f'outputs/{current_date}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate filename with full timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "param_str = f\"k{best_params['k']}_epochs{best_params['n_epochs']}\"\n",
    "filename = f\"{output_dir}/submit_BiVAECF_{param_str}_{timestamp}.csv\"\n",
    "\n",
    "# Save\n",
    "submit_df.to_csv(filename, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Submission file saved!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Filename: {filename}\")\n",
    "print(f\"Shape: {submit_df.shape}\")\n",
    "print(f\"\\nBest parameters used:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"\\nValidation Recall@{TOP_K}: {best_recall:.4f}\")\n",
    "print(f\"Expected Public LB: 0.02-0.03 (significantly lower due to validation-test gap)\")\n",
    "print(\"\\n‚ö†Ô∏è  Note: BiVAECF may underperform on 99.9% sparse data compared to EASE/BPR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÏÑ±Îä• ÏöîÏïΩ (Performance Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BiVAECF PERFORMANCE SUMMARY\n",
      "============================================================\n",
      "\n",
      "Model: BiVAECF\n",
      "Mode: FAST\n",
      "\n",
      "Best Parameters:\n",
      "  k: 100\n",
      "  encoder_structure: [100]\n",
      "  act_fn: tanh\n",
      "  likelihood: bern\n",
      "  n_epochs: 150\n",
      "  batch_size: 256\n",
      "  learning_rate: 0.001\n",
      "  beta_kl: 0.5\n",
      "\n",
      "Validation Recall@5: 0.0472\n",
      "Expected Public LB: 0.02-0.03\n",
      "Expected Private LB: 0.02-0.03\n",
      "\n",
      "Submission file: outputs/2025-11-20/submit_BiVAECF_k100_epochs150_20251120110511.csv\n",
      "Total predictions: 42410\n",
      "Cold-start users: 0 (0.0%)\n",
      "\n",
      "============================================================\n",
      "Recommendation: Compare with EASE (0.08-0.10) and BPR (0.09-0.12)\n",
      "BiVAECF is expected to perform worse due to extreme data sparsity.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BiVAECF PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModel: BiVAECF\")\n",
    "print(f\"Mode: {TUNING_MODE.upper()}\")\n",
    "print(f\"\\nBest Parameters:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"\\nValidation Recall@{TOP_K}: {best_recall:.4f}\")\n",
    "print(f\"Expected Public LB: 0.02-0.03\")\n",
    "print(f\"Expected Private LB: 0.02-0.03\")\n",
    "print(f\"\\nSubmission file: {filename}\")\n",
    "print(f\"Total predictions: {len(submit_df)}\")\n",
    "print(f\"Cold-start users: {cold_start_count} ({cold_start_count/len(all_users)*100:.1f}%)\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Recommendation: Compare with EASE (0.08-0.10) and BPR (0.09-0.12)\")\n",
    "print(\"BiVAECF is expected to perform worse due to extreme data sparsity.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cornac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}